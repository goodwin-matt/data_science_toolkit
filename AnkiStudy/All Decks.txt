What is the first step of PCA?	Standardize variables by subtracting the mean and dividing by the standard deviation. We do this because the scale differences can throw the transformations off (think about how we are finding the direction of greatest variability in the dataset).
What is the second step of PCA?	"Find the covariance matrix of newly standardized data matrix. Rember this is <img class=latex src=""latex-70ba726de31d2b513697760bec5ab4f2ed672f86.png"">"
What is the third step of PCA, after standardizing and finding covariance matrix?	Find the eigenvalue decomposition of the covariance matrix
What is the fourth step of PCA, after standardizing, finding covariance, and diagonalizing?	Multiply the standardized data matrix by the eigenvectors
How/why are eigenvalues and eigenvectors involved in PCA?	This provides a method of diagonalizing the covariance matrix. By transforming the data matrix using these eigenvectors we then will have a covariance matrix with 0's on the diagonal and variance given by the eigenvalues, implying ortogonal variables.
What is a principal component?	<div>Principal components are uncorrelated variables that are the result of an orthogonal transformation on the original variables. You can think of that orthogonal transformation as projecting each data point onto the vectors that are in the direction of greatest variability in the data. So for example, the first principal component will be the variable that goes along in the direction of greatest variability in the dataset.</div>
Why do we use principal components?	<div><div>We primarily use it as a dimentionality reduction technique by taking the top principal components that describe a sufficient amount of the variability in the data. Essentially we are finding new variables that are a combination of the old variables to better describe the data and reduce the redundancy in variables or retain the most valuable parts of all the features.&nbsp;</div></div>
What is the covariance of the data matrix?	1/nX_c'X_c (the centered data matrix). The data matrix is going to be nxp (n instances, p features). The covariance matrix will be pxp (the Sigma_ij position will be the covariance between the ith variable and the jth variable). We use the n instances however to calculate the SAMPLE covariance.
How does k-means formula work?	1. Decide on <i>k</i> (hyper-parameter), the number of clusters.&nbsp;<div>2. Choose <i>k</i> random datapoints.&nbsp;</div><div>3. Calculate the difference between each data point and each chosen <i>k </i>point. Assign each data point to closest <i>k</i>&nbsp;point.&nbsp;</div><div>4. Calculate centroid - either average or median of each cluster</div><div>5. Recalculate the distance of each point to each centroid and assign to the closest one.</div><div>6. Continue this process of recalculating centroid and reassigning until there are no more changes in assignment. Or when the centroid doesn't change anymore.</div>
What is the first step of the t-sne algorithm?	Find probabilities p_ij that are proportional to the similarity of object x_i and x_j in the high dimensional space. This is done by first finding p_j|i which is taken as the similarity of x_j to x_i and is the probability that x_i would pick x_j as its neighbor if neighbors were picked in proportion to their Guassian probability distribution centered over x_i. p_ij is then calculated as (p_j|i + p_i|j)/2N
What is the second step of tsne?	"Find a map <img class=latex src=""latex-6258dd9dd7ccc6e448272bc6e01d6eb0ac19a48b.png""> in dimension <i>d</i>&nbsp;that reflects the similarities <img class=latex src=""latex-79220e9b9f82ca92de037d2a8a6bc00ac0f9a0e0.png""> as well as possible. The way it does this is to calculate similar metrics <img class=latex src=""latex-34c18ff3f3c73e192ea30775ba0645e6cae94afe.png""> in the lower dimensions using a t-distribution since the t has fatter tails and will encode disimilar points further away from each other better. The way the points <i><b>y</b></i> are found is to minimize the Kullback-Leibler divergence between the two distributions (using gradient descent)."
What is the silloutee metric?	This takes the average intra-cluster distance (a) and the smallest average distance from each sample in the cluster to another cluster (b) and calculates (b-a)/max(a,b). 1 is a perfect score and -1 is the worse
What is hierarchical clustering?	Take two closest samples and merge and keep merging the nearest sample until all are in one cluster. Then view the dendrogram and make a decision on where to cut to create clusters.
What is/was a good reason to use PCA?	1. Correlated variables changed to orthogonal, handy when doing regression.<div>2. In todays world, a lot of models can now handle the dimensionalty problems that come with many features. PCA was/is more valuable when dealing with regressions, etc.</div>
What does it mean to have a linear dimensionality reduction technique vs. a nonlinear one?	"If f1,f2 are linear then it is a linear reduction technique. PCA is linear because f1 is a projection onto the first eigenvector, f2 onto the second eigenvector, etc.<div><img src=""15 0 0.png"">&nbsp;</div>"
What is the aim of dimensionality reduction according to the t-sne paper?	"<div>To preserve as much of the significant structure of the high-dimensional data as possible in the low-dimensional map.</div><div><br></div><div><span style=""text-align: left;"">For high-dimensional data that lies on or near a low-dimensional, non-linear manifold it is usually more important to keep the low-dimensional representations of very similar datapoints close together, which is typically not possible with a linear mapping. A manifold is simply a space that resembles a Euclidean space in some dimension.</span><br></div><div><span style=""text-align: left;""><br></span></div><div><span style=""text-align: left;"">T-SNE's goal is to keep similar points close together whereas PCA is a linear transformation.</span></div><div><br></div><div>PCA - ""<span style=""text-align: justify;"">It focuses on preserving the distances between widely separated data points rather than on preserving the distances between nearby data points."" This is because the points that are spread out will find themselves on the eigenvector of greatest variability and when it is projected on to that vector it won't be much different.&nbsp;</span></div><div><span style=""color: rgb(89, 88, 88); font-family: roboto, sans-serif; font-size: 15px; text-align: justify;""><br></span></div><div><img src=""16 1 0.png""><span style=""color: rgb(89, 88, 88); font-family: roboto, sans-serif; font-size: 15px; text-align: justify;""><br></span></div>"
How does bagging work?	Take B bootstrapped samples (from a dateset of n examples sample with replacement n datapoints and do that B times) and build a model on each bootstrapped dataset. Then average all of these. The variance should go down.
How does random forest work?	Same thing as bagging but for each tree's split we only look at a subset of the variables in order to reduce the correlation down between trees. This is because if there are few good variables for predicting they will consistently be chosen and we want to reduce that consistency. The mathematical reason for this is that while bagging reduces variance it assumes i.i.d. models but the truth is they are only i.d. and so the variance includes correlation in there.
What do ridge and lasso regression do?	lasso is the l1 norm and tends to zero out coefficients and so is a form of variable selection. Ridge is the l2 norm and reduces large coefficients to reduce overfitting
What are the linear regression assumptions?	Linear, independent for a given x the ys are independent, normal errors, equal variance
Why would we be interested in maximizing precision?	In the case of spam, out of all the ones we predicted as spam, we better hope that we got almost all right.
Why would we want to maximize recall?	Out of all the sick patients out there we want to make sure we get all of them, or as many as we can.
What is full rank mean?	If there are fewer columns than rows full rank means each column is linearly independent of each other
What are the degrees of freedom for a t distribution in the linear model?	n-p-1 where p are the number of predictors&nbsp;
What is the deviance in logistic regression?	Take 2 times the log likelihood of the saturated model minus your model and that follows a chi squared with degrees of freedom n-p. If this is big that implies the saturated is a lot better. So we reject the null that they are the same
How to handle multi class?	Train one vs all and get confidence scores or train one vs one and choose highest vote&nbsp;
"<div class=""page"" title=""Page 5"">                         <div class=""section"">                                 <div class=""layoutArea"">                                         <div class=""column"">                                                 <p>Outline how you would solve a general machine learning task<br> </p>                                         </div>                                 </div>                         </div>                 </div>"	"<div class=""page"" title=""Page 5"">                         <div class=""section"">                                 <div class=""layoutArea"">                                         <div class=""column"">                                                 <p>1. Divide your data into training (60%), testing (20%) and validation (20%) sets.</p><p>2. Build a quick model on the training data and evaluate its performance on the validation set.</p><p>3.Try other models, fix over/underfitting, etc</p><p>4. At the end, score model on test set.</p>                                         </div>                                 </div>                         </div>                 </div>"
"<div class=""page"" title=""Page 6"">                         <div class=""section"">                                 <div class=""layoutArea"">                                         <div class=""column"">                                                 <p>How do you measure a model’s quality for regression?&nbsp;</p>                                         </div>                                 </div>                         </div>                 </div>"	"<div class=""page"" title=""Page 6"">                         <div class=""section"">                                 <div class=""layoutArea"">                                         <div class=""column"">                                                 <p>R-squared, Median Absolute Error, MSE, RMSE, Mean Squared Log Error, Adjusted R-squared, AIC, BIC<br></p><p>Besides looking at metrics, we also want to look at if the model is useful. This is where Explainable AI would come in.<br></p>                                         </div>                                 </div>                         </div>                 </div>"
How to avoid overfotting?	more data. Cross validation. Jitter. Regularization like lasso
How to deal with missing values?	mean regression them or use them as a feature
Why use MSE vs. MAE or vice versa?	First of all MSE has some nice properties such as a derivative that make it useful when evaluating models. The main difference to be aware of between the two is that MSE is going to weight errors that are further away, heavier, because of the square. This could be good or bad - good if you want to penalize heavily very far off errors, and bad if they are outliers. In this latter case it might be best to use MAE
How is the false positive rate defined and what is it measuring?	FP/(FP + TN), the probability of a false alarm
How is the true negative rate defined and what other names describe it?	TN/(FP + TN) , specificity
Besides using a hold-out set what is another way of determining which model to select?	From the ideas of LIME, we can assess the features of the model for individual instances and see which features are most important. Using accuracy alone can be problematic when the top features have nothing to do with what we want. We want the model that is accurate and also make sense.
What is data leakage and data shift?	This is when you have data that is helping you make your predictions that you realisiticly wouldn't have if the model were deployed. Data shift is when your training data is different than you testing data (think geo features).
How do you get probabilities for a random forest?	For a given instance, simply take the proportion of trees that vote for a given class.
<div>What is naive about naive bayes? How do you choose your prior and likelihood functions (for each feature)?</div>	<div>We want to know P(C_k|x1, x2, ..xn). Using bayes rule we have P(C_k)P(x1,x2,...xn|Ck). We assume that these features are independent (a naive assumption) and write P(C_k)P(x1|Ck)P(x2|Ck) etc.&nbsp;&nbsp;</div><div><br></div><div>The prior can be calculated by just taking the proportion of each class in the training set.&nbsp;</div><div><br></div><div>The likelihood is a little trickier. We essentially need to make assumption for the distribution of each feature. For discrete data this might be the bernouilli or multinomial. For continuous it might be Gaussian.&nbsp;</div><div><br></div><div>Ex: for Gaussian we calculate the parameters of each distribution separately. So take x_1. Find the instances that are classified as C_1. Then estimate \mu and \sigma (Bessel corrected) using those instances. Do this for each feature, and for each class.</div>
What is the mutual information between two random variables? How is it related to correlation?	"Quantifies the ""amount of information"" obtained about one random variable through ovserving the other random variable. Determined how different the joint distribution of the pair (X,Y) is to the product of the marginals X and Y<div><br></div><div>Formally defined as:&nbsp;</div><div>{{23 2 1.png}}<br></div><div><br></div><div>{{23 2 0.png}}<br></div><div>It is more general than correlation because it is not limited to real-valued RVs and linear dependence.</div><div><br></div><div>Also known as information gain<br><div><br></div><div><br></div></div>"
<div>What is the probabilistic interpretation of AUC? What is the more technical explanation?</div>	<div>The probability that a random positive example is positioned to the right of a random negative example.</div><div><br></div><div>The more technical explanation would be to score each of your instances (typically in a validation set), rank them by score, and steadily move the threshold (determining what is a 1 or a 0) from 1 to 0. At each threshold value calculate the recall (true positive rate) on the y-axis and the false positive rate on the x-axis. The function we are dealing with goes from R^1 to R^2 where the input is the threshold valud.&nbsp;</div>
What is the out-of-bag error with regards to random forest?	<div>For each example in out training set we pass it through the different decision trees that were created using bootstrapped datasets that do NOT contain the current example. We get a majority vote as prediction on these different trees and then do this for each row of the training set. We then compare to the truth.</div><div><br></div><div>It really only makes sense to do this if you are low on data and can't afford to set aside a validation set.</div>
What is the logit function look like? What is the sigmoid function look like? What is their relationship?	Logit is simply the log odds so logit(x) = \(\log(x/1-x)\). Sigmoid is the inverse of the logit and can be written as 1/(1+e^(-x))
How is logistic regression derived?	"<div><div style=""text-align:left"">*assumptions in bold</div><div style=""text-align:left""><br></div><div style=""text-align:left"">Using the GLM framework we <b>first assume that Y_i is distributed as a Bernouilli RV </b>with parameter p_i:</div><div style=""text-align:center"">Y_i~Bern(p_i).</div><div style=""text-align:left"">We then relate $p_i$ to the <b>linear component</b> by:</div><div style=""text-align:center"">logit(p_i)=X_i \beta</div><div style=""text-align:left"">We then use maximum likelihood and assume all <b>instances are independent</b> to write:</div><div style=""text-align:left""><br></div><div style=""text-align:center"">f(Y|\beta) = \prod (1-p_i)^(1-y_i) p_i^y_i</div><div style=""text-align:center""><br></div><div style=""text-align:left"">We find however that taking the derivative and setting to 0 cannot be done algebraicly so we use a iterative method such as Newton-Raphson.</div><div style=""text-align:left""><br></div><div style=""text-align:left"">Note that the probabilities are different for each instance. Therefore when we get new data (our x_i's) then we can calculate the probability y_i is a 1.&nbsp; Related to this we can get a sense of how the different features affect the probability of Y_i being 1 by putting in a row with all zeros except for a 1 in the position corresponding to the feature we are interested in. This attempts to get at how the particular features affect the probability of a 1.</div></div>"
<div><div>How to assess overfitting? How to reduce overfitting?</div></div>	<div><div>See how you perform on your validation set and if you are performing worse then you are possibly overfitting. Add in regularization, reduce features, increase data, add in noise into your training data, do a technique called dropout for neural nets but also applied to boosted trees, reduce complexity of the features.</div></div>
What is log-loss? What is it used for?	<div><div>Log-loss is defined as:<div><br></div><div>sum over i of [-y_i*log(p_i) - (1-y_i)*log(1-p_i)]</div><div><br></div><div>This is associated with logistic regression, just the negative of the maximum likelihood.</div></div></div><div><br></div><div>Note that log loss is just the binary form of cross entropy</div>
What is entropy?	E[-log(P)], the higher this is the more randomness there is in the random variable. Entropy is the measure of the unpredictiability of the state or equivalent its average information content.&nbsp;
How does a decision tree work?	"<div style=""text-align: left;"">A decision tree is a bunch of nested binary splits that divide up the space into different areas. We then assign a constant to each area.&nbsp;</div><div style=""text-align: left;""><br></div><div style=""text-align: left;"">We have a loss function we are trying to minimize and the optimal solution would be to try all possible binary splits to minimize this function (over the training set). This splitting requires going over all possible features and threshold values for each split and essentially building all possible trees. However, this is impractical and so we take a greedy approach where at each split we choose the current best feature and threshold that minimizes the loss function</div><div style=""text-align: left;""><br></div><div style=""text-align: left;"">The question then becomes when do you stop. One criterion could be stop when the loss function does not decrease enough for a split. This is suboptimal though (proven emperically) because you might have a weak split at one level (meaning you stop) but there is a potential really good split at the next level.&nbsp;</div><div style=""text-align: left;""><br></div><div style=""text-align: left;"">A better approach is to grow out the tree completely (grow until there are certain number of points at each leaf node) and then prune it back. This pruning process seeks to minimize a function that defines the error in the terminal nodes and includes a complexity parameter over the number of leaf nodes. This parameter can be chosen by cross validation.</div><div style=""text-align: left;""><br></div>"
<div>What are the effects of multi collinearity? How do you check for multi collinearity?</div>	"<div>it makes it hard to determine which coefficients are most important because it inflates the standard erred. Also makes it difficult to make interpretations, since if we say ""holding all else constant"" but its hard to hold all else constant when correlated. The way to check this are VIFs and pairwise correlation.&nbsp;</div>"
What is cross-entropy?	<div>Cross-entropy is&nbsp;{{33 0 0.png}}</div><div>Remember that the sum is over all labels <i>for a given observation</i>. Think of it as a dummy variable, 1 for one label and 0 for the rest. The probabilities will be over all of those labels so if we are high on a false label, then we will be low on a the true label which will make the loss higher.&nbsp;</div>
What are some feature selection techniques? What are some variable reduction techniques?	<div>Feature selection might include mutual information, correlation, chi-squared test of independence, forward/backward step wise selection, lasso regression, random forest,&nbsp;<br><br>Variable reduction might include the above techniques but also PCA, tsne, autoencoder.</div>
What is entropy? What is the relation to cross-entropy?	<div>Entropy is defined as:<div>-sum_i (P_X(x_i) log_b P_X(x_i))</div><div><br></div><div>This is measuring the average rate at which information is produced by a stochastic process. We get more information out of a lower probability number showing up than a higher probability number. The highest entropy is when we have an equal balance of classes.</div><div><br></div><div>This is related to cross-entropy but instead of P in the log we have Q (hence the word cross referring to two different distributions). We use the cross entropy in terms of a loss function as well where the probability is replaced with the actual class indicator.</div></div>
What is the information gain in decision trees?	<div>This is the entropy of the parent node subtracting the <i>weighted</i> average entropy of the children nodes. The parent node should have a mix of classes (therefore a high entropy), and the children nodes should have more pure nodes therefore a lower entropy. We therefore want to maximize the difference between these.</div>
How do we get a speed up with LightGBM and XGBoost?	<div>1. Gradient based on side sampling</div><div><br></div><div><b>LightGBM</b> uses Gradient based on side sampling - saves the instances with high gradients (I'm assuming instances that have a high gradient according to the loss function) and takes a random sample of instances that have small gradients. These high gradient instances are important for reducing the loss. We remove some of the small gradients because they won't reduce the loss function that much.<div><br></div><div>2. Leaf-wise growth strategy.&nbsp;</div><div><br></div><div>This allows for more flexible trees (instead of doing level-wise growth you split based on the best leaf instead of splitting each leaf level by level). This makes leaf splitting more likely to overfit but with large datasets this isn't as much of an issue so we like the flexibility. <b>Both now use this</b>. Note that both leaf wise growth and level-wise growth will eventually lead to the same tree, its just that leaf wise growth is concentrating on the nodes that will reduce the loss the most and so it more quickly gets to a better tree on the training dataset (and therefore more likely to overfit). This implies that leaf-wise growth can happen at any level, doesn't have to keep going down and down levels. You might split on some leaves down below but the next best one to split on is on a higher level so you go back.</div><div><br></div><div>3. Binning</div><div><br></div><div>Another that <b>both</b> use is binning the features in order to be quicker at determining split points.&nbsp;</div><div><br></div><div>4. Exclusive Feature Bundling&nbsp;</div><div><br></div><div>This essentially bundles features together that are never non-zero together, reduces the dimensionality of the problem. <b>LightGBM</b> uses this.</div><div><br></div><div><br></div><div><br></div></div>
How to get feature importance from a decision tree?	One of the more common ways of doing this is using the Gini importance. This is done by calculating for each node the following:<div><br><div>Gini impurity of root node (weighted by number of instances in node) minus gini impurity of one branch minus gini impurity of the other branch (both weighted).&nbsp;</div></div><div><br></div><div>Call this value x_i where i indexes each split in the decision tree. Then since each split is associated with a feature we add up all the x_i's for a given feature and divided by all x_i's over all features. We do this for each feature and then we can normalize between 0 and 1 for each feature by dividing by all the summed feature importances.</div><div><br></div><div>This is then applied to random forests by averaging over the trees for each feature.&nbsp;</div>
What is the Gini Impurity and Gini Gain?	<div>Same idea as the information gain but instead of entropy we use gini impurity which is defined as:</div><div><br></div><div>sum_i (P_X(x_i) (1- P_X(x_i))</div><div><br></div><div>This sum is over the <i>classes</i>&nbsp;in the node. The probabilities are estimated using the proportions. Another cool way to think of the gini impurity is the probability of being wrong (think of the law of total probability and that 1-P_X(x_i) is the conditional probability.</div><div><br></div><div>gini gain is just the difference between the gini impurity of the parent and the <i>weighted </i>average of the gini impurity of the children<br><div><br></div></div>
How do decision trees deal with multi-class output?	It deals with it quite naturally actually. The instances are directed to the different children nodes according to some feature. Those children nodes will have potentially muli class instances. We classify the instances in that node with the majority class, or split again.
<div>What are pros and cons of decision trees?</div>	"<div><div><div><div style=""text-align:left"">Pros:&nbsp;</div><div style=""text-align:left""><ul><li>They automatically take into account interactions<br></li><li>Can model nonlinearities better</li><li>Can be interpretable, can be visualized</li><li>Able to handle numerical and categorical data</li><li>Able to handle multi-output problems</li></ul><div>Cons:</div><div><ul><li>High variability (therefore more likely to overfit)</li><li>Naturally piece wise functions (a 45 degree line could be optimal but DT would have a hard time with that)</li><li>Can be biased in imbalanced datasets because each split will try and find pure nodes which may be biased (called frequency bias) towards the majority class. However, it depends on the data because if there is a region that has the minority class almost exclusively it may be able to find that.</li></ul></div></div></div></div></div>"
Why use precision-recall vs. roc?	<div>When we use roc on an imbalanced dataset our ability to get true negatives can overwhelm how we are doing on the positive examples (think of this as the TPR stays the same at each threshold, but the FPR would increase because the denominator is smaller and so the who curve shifts right). Precision will focus on those positive examples.</div>
How do you deal with an imbalanced dataset?	"<ol><li style="""">Undersampling - remove samples from the majority class (random undersampling, cluster centroid). Undersample might be best when you have a lot of data. Cluster centroid is where you do clusters and use the centroid as the instance of choice.</li><li style="""">Oversampling - randomly sample duplicates of the minority class, SMOTE. Oversample might be best when you don't have as much data. SMOTE takes a random k nn and creates a point somewhere between them.&nbsp;</li><li style="""">Change the performance metric (use recall, precision, balanced accuracy, etc).&nbsp;</li><li style="""">Cost-sensitive learning (change the loss function so that we are penalized more when we misclassify the minority class)</li><li style="""">Use decision trees (could work well if the minority class is in a specific space within the feature space)</li></ol>"
Why are decision trees robust to outliers in X?	Because split points are chosen based on sample proportions it doesn't matter how far they are away.
What are some important parameters of decision trees?	<div><div><div><div>1. Criterion - how do we determine the split to make? (gini, or entropy) Gini may be preferred since log is slightly more expensive to calculate in the entropy</div><div><br></div><div>2. Max depth - the max depth of the tree. If none then tree goes until all nodes are pure or all nodes have less than the min_samples_split</div><div><br></div><div>3. min_samples_split - the number of samples required to split a node, default is 2</div><div><br></div><div>4. min_samples_leaf - the number of instances that must be in each final leaf when considering a split</div></div><div><br></div><div>5. max_features - the number of features to consider at each split. Most useful for random forest</div><div><br></div><div>6. max leaf nodes - grow tree in best-first fashion (leaf-wise growth, concentrate on nodes that that reduce the loss the most). This parameter will control how many of those leafs to split.&nbsp;</div><div><br></div><div>Other parameters are variations of how to stop.</div></div><div><br></div><div>Can also weight each class if one is more important?</div><div><br></div><div><br></div><div>Return:</div><div><br></div><div>1. predict_proba - just calculate the proportion that are of the same class in the final leaf</div><div><br></div><div><br></div></div>
How does general boosting work?	"<div><b>High level</b>: Combines the outputs of many ""weak"" learners (a model that does only slightly better than random) and produces a powerful ""committee"".&nbsp;</div><div><br></div><div><b>Detail:&nbsp;</b>One common approach when approximating functions is to do a basis function decomposition; decompose a function down into more simple functions. This is essentially what boosting is doing, finding simple models that when combined approximate the function.</div><div><br></div><div>The way it does that is to use what is called a forward stagewise additive model. We train an initial weak learner on the training dataset, find the residuals, and then train another weak learner that focuses on the instances we were wrong on.</div><div><br></div><div>There are different flavors of doing this such as AdaBoost, but more common is to use the gradient learning paradigm. We've trained a weak learner and then we subtract a step size and the gradient of the loss function where the loss function is between the training data labels and the weak learner just trained. The next weak learner then approximates that gradient of the loss function.</div><div><br></div><div>Its important to note that it won't fit the loss function perfectly, so therefore there is sort of an automatic prevention of overfitting to the training set.&nbsp;</div><div><br></div><div><br></div><div><br></div>"
<div>How does gradient boosting work? What are the parameters to be aware of?</div>	"<div><div>In that forward stagewise additive paradigm this is using the gradient descent paradigm to accomplish that process.</div><div><br></div><div>Another way to think of it is we train a weak learner, get the residuals, see that there is still a pattern within the residuals so train a model on the residuals and add that to the original model and thereby ""correcting"" it.</div></div><div><br></div><div>Note that there is a natural prevention of overfitting because our succeeding weak learners won't fit the loss function perfectly. But in general, since we are using the gradient descent paradigm we have all of the tools available to prevent overfitting (including the descent algorithm itself) but also things like the learning rate, number of trees, dropout (called dart), lasso/ridge, etc.&nbsp;</div><div><br></div><div><b>Parameters to be aware of:</b></div><div style=""text-align:left""><ol><li>Size of trees (num_leaves, max_depth)</li><li>Shrinkage (the step size or learning rate)</li><li>Number of boosting iterations or num estimators (tied together with step size, smaller step size needs more estimators)</li><li>subsample for binning (one of the speed ups for light gbm)</li><li>objective function to use</li><li>class weighting when dealing with unbalanced data</li><li>min_split_gain, min_child_samples: parameters controlling how deep to go on the trees</li><li>l1 and l2 regularization terms</li><li>importance type - could be number of splits a feature appears in or gain - total gain of splits which use the feature.</li><li>If doing stochastic gradient boosting we can choose the number of training examples to look at (reduces the training time and can make it more accurate)</li></ol></div><br>"
What is Mahalanobis distance?	"<div style=""text-align: left;""><span style=""font-family: &quot;Helvetica Neue&quot;; font-size: 12px;"">Mahalanobis distance is calculated by (y-\mu)’ E^-1 (y-\mu).</span><span class=""Apple-converted-space"" style=""font-family: &quot;Helvetica Neue&quot;; font-size: 12px;"">&nbsp; </span><span style=""font-family: &quot;Helvetica Neue&quot;; font-size: 12px;"">This essentially finds how many standard deviations away the point is taking into consideration the covariance structure of the data. We are not only concerned about distance from the mean but also direction&nbsp;</span></div><div style=""text-align: left;""><span style=""font-family: &quot;Helvetica Neue&quot;; font-size: 12px;"">This helps us find outliers. One variation might be to transform the data and then find the Mahalanobis distance.&nbsp;</span></div>     <style type=""text/css""> li.li1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'Helvetica Neue'} ul.ul1 {list-style-type: hyphen} </style>   <ul class=""ul1"">  </ul>"
How to get feature importance for parameterized regression model?	DON'T Directly compare coefficients, they will be on a different scale, don't compare p-values.<div><br></div><div>Its ok to compare coefficients if all predictors are standardized. Another method is to measure the change in R^2 when a variable is added after all other variables.&nbsp;</div>
How to deal with skewed dataset? In linear regression what are we trying to fix?	"<div style=""text-align: left;"">Do a transformation. There are different transformations out there including the log, square root, cube root, etc. Box-cox method can help us find the right power transform.</div><div style=""text-align: left;""><br></div><div style=""text-align: left;"">The way to do this is to first fit a naive model and look at the residual plots. In particular with linear models we are looking to fix assumptions that have been violated.&nbsp;</div><div style=""text-align: left;""><ul>    <li>Linearity: by doing a log transform it might make it more linear</li> <li>Normality of errors: its possible that our errors are skewed, so doing a transform will fix that</li> <li>Equal variance</li>   </ul></div><div style=""text-align: left;"">The question becomes do we want to transform Y, X, or both.<br></div><div style=""text-align: left;""><br></div><div style=""text-align: left;"">X: might lessen the influence of the biggest X's, fix model curvature with respect to X</div><div style=""text-align: left;""><br></div><div style=""text-align: left;"">Y: makes the data linear, remove skew in residuals, aleviate heteroskedacity</div><div style=""text-align: left;""><br></div><div style=""text-align: left;"">Both: The uneven scale might hide the relationship, might make sense to think in multiplicative terms. For someone in th eupper echelons of income 2M vs 2.1M just as 200k vs. 210k is no big deal for someone with lower income.&nbsp;</div><div style=""text-align: left;""><br></div><div style=""text-align: left;"">Advantage with log transform is no negative predictions, even though you might predict something negative on the log scale to transform back its e^prediction.</div><div style=""text-align: left;""><br></div><div style=""text-align: left;""><br></div><div style=""text-align: left;""><br></div><div style=""text-align: left;""><br></div><style type=""text/css""> li.li1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px 'Helvetica Neue'} ul.ul1 {list-style-type: hyphen} </style>"
Why is AUC inflated when we have an imbalanced dataset?	This is because the False Positive Rate is so low because of the denominator being so high
How to get probabilities from gradient boosting? How to get the predictions?	"<div>get probabilities of positive class from each base tree. Since boosting is just a GAM then we relate the GAM to the logit function (log-loss, cross-entropy). We add up those separate probabilities and the do sigmoid transform to put between 0 and 1</div><div><br></div><div><a href=""https://stats.stackexchange.com/questions/395697/what-is-an-intuitive-interpretation-of-the-leaf-values-in-xgboost-base-learners/"">https://stats.stackexchange.com/questions/395697/what-is-an-intuitive-interpretation-of-the-leaf-values-in-xgboost-base-learners/</a><br></div><div><br></div><div>To get predictions, I believe lightgbm just takes the max probability (which for binary would be thresholding it at 0.5.</div>"
What is SMOTE?	"Synthetic Minority Over-sampling Technique. This is a way to oversample the minority class.&nbsp;<div><br></div><div>1. Take a sample from the minority class.</div><div>2. For each instance, consider its <i>k </i>nearest neighbors.</div><div>3. Take the vector between one of those neighbors and the current instance and multiply by a random number between 0 and 1. This is the new data point of the minority class</div><div><br></div><div>Whats nice about Smote is that you soften that decision boundary bias by adding in more relevant examples. See&nbsp;<a href=""http://www.chioka.in/class-imbalance-problem/"">http://www.chioka.in/class-imbalance-problem/</a>&nbsp;for good description.</div><div><img src=""Screen Shot 2020-09-02 at 9.07.46 PM.png""></div>"
What is the cluster centroid approach for unbalanced data?	This is an undersampling technique where you collapse the number of instances down in the majority class to their centroid for however many <i>k </i>centroids you want to have.
What is balanced accuracy?	(TPR + TNR)/2
How does light GBM get its feature importance scores?	"Default is ""split"" which will count how many times that feature is used in a model.&nbsp;<div><br></div><div>Another option is ""gain"" which sums up the gains of the splits that use the feature.</div>"
Describe what Jenkins does	Jenkins is an open source tool that facilitates continuous integration.&nbsp;<div><br></div><div>The process looks like this:</div><div>1. Developer commits code to shared repository</div><div>2. Jenkins regularly checks for changes. Once a change is detected it triggers a build.</div><div>3. If build fails, team is alerted.</div><div>4. If build is successful, tests are run.</div><div>5. If tests successful, pushed to stage, and then to prod.</div>
What is K8?	Kubernetes provides a framework to run distributed systems resiliently. Takes care of scaling and failures and provides deployment patterns.<div><br></div><div>The whole goal is to take the resources that are on the cluster and make sure people can make requests and run workloads (typically docker).</div><div><br></div><div>The user talks through the load balancer</div>
What are the different philosophies of Spark?	1. Unified framework - the API is consistent<div>2. Focusing on a computation engine - doesn't care where the data resides. This is different from the Hadoop paradigm where it worried about storage (distributed cheap storage) and computation (map/reduce framework)</div><div>3. Libraries - this is where most of the development is happening.</div>
Why does Spark even exist?	Historically, the processors for computers would get faster and faster, and so applications could naturally scale up. However, we are running into hard limits for how fast this processors can go, so to scale up we switched to doing multiple cores. At the same time, more and more data is being collected, faster than we can process it. Parallel computing is the way of the future then.
What is a cluster manager?	This is a computer or node that manages the cluster and determins how everything works together. This would be Sparks standalone cluster manager, YARN or Mesos.
Why is Parquet a better approach for big data?	It saves data in columnar format. This is good because:<div><br></div><div>1. Its easy to compress a column of data since the data is more homogenous</div><div>2. Sometimes we only want to read in a few columns at a time</div><div>3. Each column should typically have the same datatype.</div>
What are the acceptable partition sizes in a Parquet dataset?	Anything below 1k is probably too small, and anything above 100Mb is probably too big
How do you measure a classifier performance?	<p>Confusion matrix, Accuracy, Precision, Recall, F1-score, Log-loss, AUC, Specificity</p><p>Besides looking at metrics, we also want to look at if the model is useful. This is where Explainable AI would come in.</p>
What does . , \w, \d, \s, \W, \D, \S do in regex?	Period is for any character, \w is for an word character, \d is for any digit, \s is for white space, and the capital versions are for anything but those things
What does [abc], [^abc], and [a-g] do?	Matches any character in a, b, or c, matches any character that is not in a,b, or c, and matches in character in a-g.
What does ^abc$	This would grab any line that starts with a, has a b in the middle and ends in c.
What does \b\w*\b do?	This gets any word. The \b is a word boundary, \B is a non-word boundary
What is a*, a+, a?	0 or more a's, 1 or more a's, 0 or 1 a
What is a{5}, a{2,}	5 a's and 2 or more a's
What is a{1,3}	Between 1 and 3 a's
ab|cd	Match ab or cd
Whats the Span of a collection of vectors?	The set of all linear combinations of those vectors.
How do you normalize a vector?	Divide by its unit vector which is denoted ||u|| and defined by the square root of the sum of the squared elements.
What is linearly dependent and linearly independent? How do you determine if it is linearly independent?	If the only values for your constants in a linear combination of the vectors are 0's to get you to equal 0, then we have a linearly independent set. We can check linearly independence by solving a system of equations.
What is a linear subspace of R<sup>n</sup>?	It is a subset vectors of R<sup>n </sup>such that it contains the 0 vector, closed under multiplication (multiply it by a constant and resulting vector is also in subset) and closed under addition.
What is a basis?	The minimum set of vectors that spans the subspace, must be linearly independent.
What is reduced row echelon form?	All of the leading 1's are the only non-zero elements in their column. If any all zero row then last row.
What are pivot columns and free columns when dealing with reduced row echelon form?	Pivot columns are your leading 1's, free columns are where there are non-zero variables that aren't leading 1's.
System of linear equations - when is it no solution, unique solution, and infinite solutions?	No solution is when we do row echelon form and get 0=4 or something. Essentially we are talking about planes that never intersect. Unique solution is when we have enough constraints, and infinite solution is when you have free variables.
Whats the derivative of sin(x)? Of cos (x)? Of tan(x)?	cos(x), -sin(x), sec<sup>2</sup>(x)
Whats the log base change formula?	log<sub>b</sub>(x) = lob<sub>c</sub>(x)/log<sub>c</sub>(b)
Whats the derivative of a<sup>x</sup>?	ln(a)a<sup>x</sup>
Whats the integration by parts formula?	\int udv = uv - \int v du
What is big-Theta of n mean? What does big-O of n mean?	big-Theta of n means that the running time is at least some function of n times a constant, but no more than some function of n times another constant. Big O means there is an upper bound function.&nbsp;
What is the ranking of these functions from slowest to fastest growth?<br><div>O(n<sup>3</sup>), O(1), O(nlog<sub>2</sub>(n)),&nbsp;&nbsp;O(n), O(2<sup>n</sup>), O(n!), O(log<sub>2</sub>(n)), O(n<sup>2</sup>)</div>	O(1), O(log<sub>2</sub>(n)), O(n), O(nlog<sub>2</sub>(n)), O(n<sup>2</sup>), O(n<sup>3</sup>), O(2<sup>n</sup>), O(n!)
What is the null space of a matrix A?	This is the subspace of vectors x that satisfy the homogenous equation Ax=0.
How do you find the null space of a matrix?	Solve the homogenous equation and write it in terms of x_2 * a vector + x_4 * a vector for example, or all linear combinations of those vectors.
What does it mean when the only vector in the null space of A is the 0 vector?	Then the columns of A are linearly independent.
What is the column space of a matrix? What if I say b isn't in the column space of A?	This is the span of the columns of the matrix. This would mean Ax cannot equal b, because the column space will be all vectors of Ax.
What is the nullity of A?	This is the dimensionality of the null space of A (the number of basis function that span the null space). Turns out that this is the number of free columns in the reduced row echelon form of A.
What is the rank of a matrix?	This is the dimenionality of the column space (or number of basis functions) that span the column space. Turns out the basis is the columns that are the pivot columns in your reduce row echelon form.&nbsp;
When thinking of matrix/vector multiplication how does the columns come into play?	You can think of each element of the vector being multiplied by the corresponding column of the matrix and all added together.
What is a linear transformation?	T(a+b) = T(a) + T(b) and T(ca) = cT(a)
For a linear transformation how do you get it in matrix form?	You take the identity matrix and do the transformation on each column.
How do you do a rotation in R2?	cos(theta) is adjacent/hypotenues, sine(theta) is oposite over hypotenuese, which if our hypotenuese is 1 then sine(theta) will be the length of the oposite for example.
What is the projection of vector x onto some vector L?	We know that x - proj<sub>L</sub>(X) is orthogonal to L. Using this we can derive the following formula:<div>(x.dot(v)/v.dot(v)) .dot(v)</div>
How do you write out the solution set of a system of equations?	You would write the vector [x1, x2, x3, x4] for example is equal to x3*[1,2,0,0] + x4* [2,3,4,0] for example.
How do you solve for the inverse of a matrix?	Augment it with the identity matrix and put into reduced row echelon form.
What is an eigenvector and eigenvalue?	Ax = lambda x, x would be an eigenvector and lambda would be the eigenvalue
If you have linearly dependent columns can you invert the matrix?	No
What does it mean to have a zero determinant?	A is not invertible, rows are linearly dependent and columns, the system of homogenous linear equations has a non-trivial answer (comes into play with eigenvectors).
How do you solve for eigen values?	Take the determinate of lambda I - A and set equal to zero and solve for lambda. This is called the characteristic equation.
Whats the Eigenspace of an eigenvalue?&nbsp;	This is equal to the null space of that eigenvalue times I - A.
How do you solve for an eigenvector given an eigenvalue?	You essentially find the null space by finding the collection of vectors that span that null space. Remember that this is done by reduced row echelon form and then getting the solution set and seeing what the span would be.
What does coordinates with respect to a basis refer to?	When we say (3,1) on a standard euclidean plane we are defaulting to the standard basis so we multiply (1,0) by 3 and add (0,1) *1.We are representing some vector with respect to a certain basis.
What are the techniques for computing limits?	"For ""nice"" functions you can just plug in the value of the limit you are going to, to get your result. But limits really care about the behaviour arount the point, its just that for nice functions the behavior around and at are the same.<div><br></div><div>Knowing this when we get 0/0 for example, we can try to simplify by factoring, multiplying out, or making it unrational by multiplying by (a-b), factoring out the biggest term works as well</div>"
Whats the squeeze theorem?	This says that for f(x)≤h(x)≤g(x) if the limit of f(x) and g(x) both equal L then the limit of h(x) will also be L.
What happens when in the limit one function goes to infinity and the other goes to a negative number in multiplication?	This would be -infinity
What are \., \*, and \\, \t, \n, \r	The first three escape special characters then you have tab, linefeed, carriage return
What is a capture group?	This is denoted by (abc) for example so if we do (abc){3} then we will get abcabcabc
What is a backreference?	This is denoted \1. If we have (abc|def)=\1 then we would have abc=abc and def=def but not abd=def or def=abc since the reference will be whatever the capture group is.
What is a positive and a negative lookahead?	q(?=u) would find q followed by u but just give us q. q(?!u) would find q not followed by u but just give us q.
What does the Central Limit say?	For a i.i.d. random sample X_1, X_2, ..., X_n where X_i has mean mu and sd sigma, then X_bar is distributed as a N(mu, sigma^2/n).&nbsp;
What is the sampling distribution?	This is the distribution of X_bar. Imagine taking many, many samples from the distribution of X and averaging each sample and plotting those averages on a histogram.
What is a z-score?	This is essentially how many standard deviations away from the true mean a sample mean is. It is given by X_bar - mu/(sigma/sqrt(n))
What is a type 1 error and what is another way to say it?	This is when we reject the null hypothesis when it is actually true. The probability of this is alpha. This is also the false positive finding (positive referring to how we reject the null and say there IS an effect. If the null is true then the two means for example should really be equal.)
What is a type 2 error and what is another way to say it?	A type 2 error is when we fail to reject the null hypothesis when we should have. This is represented as beta. This is also referred to as a false negative (negative referring to the fact that we found no difference between the means for example).
When do you use the Bonferroni correction and what is it?	You use Bonferroni when you are doing multiple tests at once (for example between two groups you test the difference between multiple features). The correction is to take your alpha level and divide it by the number of tests or alpha/n
Why do statistical significance tests pick up small effects when dealing with big data?	If you think in terms of the central limit theorem our variance between the null distribution and the alternative gets smaller and so we pick up on effects. Imagine flippin 1 million coins. If we got 520,000 tails we'd feel more confident the coin is biased vs. if we flipped 100 coins and got 52 tails.&nbsp;
What is a covariance matrix?	Each element of the matrix gives the covariance between the ith element and jth element of a single random vector. A random vector is a random variable with multiple dimensions.
What is the cross-covariance matrix?	Same thing as covariance matrix but between two different vectors
Transformation of Y=g(X)?	\(f_y = f_x(g^{-1}(y))|\frac{d}{dy} g^{-1}(y))|\)<div>0 otherwise</div>
What is the formula for the prediction interval?	x_bar +- t sqrt(s2/n + s2)<div><br></div><div>We add in the extra s2 because that is the variance of the observations but this assumes independence between mean individual variance of sum&nbsp;</div>
What is the F-test?	between groups variance/within groups variance
What are the total degrees of freedom and for f test and t test?	the total degrees of freedom are n-1 and for t stat it’s n-p. For f it’s p-1 on top and n-p on bottom&nbsp;
What do you need to find p(x&gt;y)?	the joint distribution
What is a paired t test?	this is when you have a before and after in the same group. You take the differences of each subject and then do a one samba t test
What is the moment generating function&nbsp;	E(e^Xt)
<div>What happens to correlatione when we scale and add?</div>	<div>correlation is the same&nbsp;</div>
What is generalized sample variance?	(volume)^2/(n-1)^p where the volume is the box formed by x_(1)....x_(p) (the features)
What is alpha in stats tests?	Significance level
What is the critical value?	That is the value associated with \alpha that tells us when to reject/accept null hypothesis.
What is the likelihood function?	This is a probability density function but where the input is a paramter, not a data point.
What is a permutation test trying to get at?	<div>Whether the two random variables we have samples for are drawn from the same distribution. For example, if we have samples from group A and samples from group B we can calculate the difference between the two averages and save that value. Then we mix up the labels of the samples and calculate the differences to create a distribution. We can then calculate a p-value on that distribution with the true difference that we saved.</div>
How to check if assignment to various buckets in A/B test are random?	Plot the distributions for a couple of variables and see if they are roughly the same. You can also do a permutation test where you group everything together and see if the difference between groups on the variables we aren't testing are the same?
What is the benefit of doing an A/A test where we put into random buckets but give the same exact treatment?	To see if the sampling algorithm is truly random because if it is random we shouldn't see any significance results between the two buckets.
How do we do an A/B test with many variants?	Have one control and many treatments and make pairwise comparisons with the control group using a Bonferroni correction.
What is MAP, MLE, and MOM?	Maximum a posterior - MLE is a MAP when the prior is uniform. Method of moments&nbsp;
Do we want unbiasedness for a parameter in inference? What about for predictive modeling?	Yes for inference since we are trying to estimate a parameter. For predictive modeling we priortize generalizability and if we are too unbiased this could mean the variance is high (between training sets) which could mean our genearlizable error is high.
Explain differences between Bayes and frequentist	<div>bayes treat to parameter of interest as a random variable. &nbsp;Frequentists treat it as fixed and probability as the long term frequency of something. We then compare the fixed value to the long run behavior of the the value (meaning in the long run it would be extremely unlikely possibly to get this value so we reject).</div>
<div>What are the three assumptions for using t-test or z-test?</div>	<div><div><div><div><ol><li>Randomization (to make sure the groups are similar)<br></li><li>Independence (independence between groups and within groups) If this assumption is violated then you could have skewed results.</li><li>Normality (even t-tests assume this since it assumes that X_bar is normal.) T-test assumes s^2 follows a chi-squared distribution</li></ol></div></div></div></div>
How do we find the t-stats for each beta?&nbsp;	We take the variance of the betas which we find to be sse/n-p multiplied by \((x’x)^{-1}\) and take the diagonal &nbsp;then we go betahar divided by those variances&nbsp;\(\sqrt(x)\)
<div>Why do we do bessels correction?</div>	When calculating the bias of the statistic by dividing by n-1 we make it unbiased. The bias comes from subtracting each sample value from the ESTIMATED mean
When to do a one direction test vs. a two direction test?	We do a one direction test only if we don't care about the other direction. If we do simply greater than for example and the test fails, we don't know if it was just as good or worse than. If we do care about either direction then we should do a two directonal t-test
When do we use the rank sum test vs. the t-test?	We do this when our normality assumption is violated for the t-test. However, if n is large enough then the central limit theorem will apply and it may not be as big of a deal. If there are unequal variances then use the welch test.
When to use the Wilcoxon-signed rank test?	If we feel our data is not normally distributed and our n is small. This is used in the <i>paired </i>t-test scenario. This is done by taking the absolute value of each pair, ranking them, and multiplying that ranking by its sign (instead of absolute value see if the difference is positive or negative). If one of the sample is consistently positive then we will have a higher statistic and therefore reject the null that they are the same.
What is the high level interpretation of statistical significance?	A result that is unlikely due to chance. Doesn't necessarily mean practical significance.
<div>What is power? Why do we care about it?</div>	<div><div>The probability that we reject the null hypothesis given our alternative is true. This is defined as 1-beta. We can also think of it as the probability we get a statisticaly significant result assuming the alternative is true. The probability the test finds significant results.</div><div><br></div><div>The power is related to sample size, effect size, and signficance threshold. Something for me to keep in mind is that type 2 and and type 1 error are almost independent from one another. Type 2 error is with respect to the alterhative hypothesis whereas type 1 is with respect to the null distribution. So I think the way to look at the power is another measure of how good our statistical test is. With larger sample sizes our type 1 error doesn't change because that what our test is controlling for. However, the type 2 error will change and so we would prefer tests with higher power.&nbsp;</div><div><br></div><div>The way we use power is throgh power analysis where we see how many samples we need to reasonable deted some effect size or with a certain sample size budget do we have reasonable power?&nbsp;</div></div>
What are variance inflation factors?	This is where you take each predictor and regress it on the other predictors. You then get the R^2 from that model and calculate \(\frac{1}{(1-R^2)}\). So if X is independent of the other predictors then R^2 will be low and VIF will be close to 1. If it is related then R^2 will be high and so will the VIF
Why are the beta hats in regression t distributed?	<div>beta hat is distributed normal since it’s a linear combo of the normal. We can standardize it (subtract the true beta coefficient and divide by the standard deviation of the distribution of beta) we end up with a standardized normal. We can then assume out true beta coefficeint is zero and do a statistical test.</div><div><br></div><div>However, our standard deviation is an estimate that is distributed as a chi square, and a normal divided by a chi-square gives a t distribution. The n-p degrees of freedom comes from the estimate of the standard deviation. Normally its n-1 for other degree of freedom scenarios, but we are estimating p parameters here, and so we divide by n-p to keep the estimate unbiased.</div>
What are the issues with multicollinearity in regression? How do we diagnose it? What are some solutions?	<div><div>The issue with multicollinearity is that it makes the individual estimates of the coefficients more uncertain. This is because the standard error of a beta coefficient can be written in terms of the VIF of that coefficient and so if those are high (meaning X_j is correlated with the others) then the standard error will be high and we will be less certain of the actual coefficient.</div><div><br></div><div>Intuitively the interpretation of the model is lost because we say as you increase by one unit, <i>holding all else constant, </i>then the dependent variable does blah. However, if the predictors are correlated, its hard to hold all else constant.<br><div><br></div><div>This is one way you diagnose it, if you take out another correlated coefficient and you see a large swing in the other coefficients.&nbsp;</div><div><br></div><div>Some solutions are to remove coefficients that are correlated, PCA, etc.</div></div><div><br></div><div>Its not an issue when it comes to prediction however.</div></div>
Why check residual plots?	If they show a pattern it means your linear model is underspecified, its biased, you are missing out on other variables.
<div><div><div>What does r^2 represent? Alternative interpretations? What are some downfalls? What is the adjusted R^2?&nbsp;</div></div></div>	<div><div><div>This is the coefficient of determination. It estimates the fraction of the variance in Y that is explained by X in the regression.&nbsp;</div><div><br></div><div>You can also think of this as the sample squared correlation between (the difference in observed and grand mean) and (the difference between regression line and grand mean), which is the Pearson correlation coefficient between the observed y and the predicted f, where f has an intercept term.</div></div><div><br></div><div>R^2 should be between 0 and 1 but sometimes do to computations can be negative.</div><div><br></div><div>R^2 will always improve with more predictors so adjusted R^2 will penalize on the number of predictors.&nbsp;</div></div><div><br></div><div><br></div>
When is R^2 high enough?	R^2 being high enough is dependent on the domain. Some domains will just inherently have more unexplainable variance, so in this sense a low R^2 might not be terrible (for example in human behavior studies).&nbsp;<div><br></div><div>Really the question should be if our main goal is interpretation or prediction. If interpretation the R^2 is less relevant. We instead care if the model makes sense with our data.</div><div><br></div><div>If it is prediction however, we may care more. A better question to ask however is if the prediction intervals are precise enough for the domain.<br><div><br></div><div><br></div></div>
What is the f test for regression?&nbsp;	<div><div><div>Ssr/(p-1)/sse/(n-p)</div></div><div><br></div><div>Sum of squared error is the squared difference between the point and the model. Sum of squared regression is the difference bewteen the model and the grand mean (between groups variability).</div></div><div><br></div><div>Two chi squared divided by each other</div>
What are some other regression diagnostics?	Residual plots, Q-Q plots of residuals (comparing theoretical position and actual), F-test, R^2, AIC
What is a confidence interval and how do you interpret it?	<div>I think its best to think of a confidence interval as a the theoretical probability around the parameter of interest. To get to that though its insightful to think of it first in terms of the test statistic and use the test statistics distribution for a given confidence level. For example, with the t statistic:</div><div><br></div><div>P(-c &lt; T &lt; c) = 0.95</div><div><br></div><div>where T = (X_bar-\mu)/sqrt(s^2/n)</div><div><br></div><div>rewriting this we would have:</div><div>P( X_bar - sqrt(s^2/n)*c &lt; \mu &lt;&nbsp; X_bar + sqrt(s^2/n)*c) = 0.95</div><div><br></div><div>This is in theoretical land however, everything above is valid. The theoretical X_bar minus mu will be zero for example. When we take an actual sample however, we have to go to that frequentist interpretation which is that the true value \mu is either <i>in or not in </i>the CI,&nbsp;but over repeated sampling it will be in 95% of those intervals.</div><div><br></div><div><br></div>
What is the correlation called between two continuous variables? What about two ordinal categorical variables? What about two nominal variables? What about between continuous and binary? What about between two binary variables?	"<ol><li style=""text-align: left;"">Continuous: Pearson correlation<br></li><li style=""text-align: left;"">Two ordinal, categorical: Spearman - this is a correlation based off of ranks (measuring if there is a monotonic relationship). Equivalent to the Pearson correlation if calculated on the ranks of the variables.</li><li style=""text-align: left;"">Two nominal variables: Chi squared test</li><li style=""text-align: left;"">Cont. and binary: point-biserial correlation coefficient, equal to Pearson</li><li style=""text-align: left;"">Binary variables: Phi coefficient, a Pearson between two binary variables returns the phi coefficient</li></ol>"
What is the Chi-square independence test?	"<div><div>Tests if two categorical variables are independent from one another.&nbsp;</div><div><br></div><div>The null hypothesis is that they are independent. The alternative is that there is an association.&nbsp;</div><div><br></div><div>The way we do this test is to build a contingency table. So say we have variable that has three categories and another variable that has two categories. We would then create a 3x2 table where the entry in each cell is the number of instances that have that combination. Then we calculate the marginal counts and get the marginal probabilities. We then calculate the expected value for each cell by taking the joint probability (the marginals muptiplied together since we are assuming independent) and multipliying that probability with the total count.</div><div><br></div><div>We then take the square of the observed - expected divided by expected and add those up for all cells. If this is large then we would get a low p-value and then reject the independence assumption (the notion that we can multiply our marginals together). DF are (rows - 1)(columns - 1) which is confusing to me since a chi squared is derived from adding up how many normals so should be rows*columns in my book.</div><div><br></div><div style=""text-align:left"">Assumptions include</div><div style=""text-align:left"">1. random sampling</div><div style=""text-align:left"">2. the expected value must be 5&gt;</div><div style=""text-align:left"">3. Independence</div><div style=""text-align:left""><br></div></div>"
What is skewness?	This is defined as the third standardized central moment. A skew of 0 means a symetrical distribution. Exponential, which is really skewed has a skew of 2.
<div>When do you use the t-test vs. z-test?</div>	<div><div>Both tests require that the distribution be roughly normal. This is determined if n&gt;30 because of the central limit theorem we feel comfortable. If n&lt;30 then we don't feel comfortable and need to use the rank-sum test.<div><br></div><div>The main differentiator between these two however is if we know the true standard deviation or not. If we do then use the z-test. Most times we don't though. In that case we use the sample standard deviation. Since there is an unknown component to that however we treat the sample variance as coming from a chi-squared distribution with degress of freedom n-1. A normal divided by a chi squared distribution is a t distribution.&nbsp;</div></div><div><br></div><div>The reason its a chi-squared distribution is because its a sum of squared standard normals.</div></div>
What is confounding?	<div>This is when you have a variable YOU DID NOT MEASURE that explains the two variables you did measure (Age affects Shoe Size and Literacy Rate). The causation relationship is between age and the two variables and the correlation is between the shoe size and literacy.</div>
How does the rank sum test work or the Mann-Whitney Test?	<div><div>You use this test is you can't claim normality on your data. The assumption is that your data is independent still and although not normal have the same shape.</div><div><br></div><div>Tests whether the two samples were selected from the same distribution.<br><div><br></div><div>To do this test you combine the two groups together and rank them from smallest to largest. If there is a tie you assign the same ranking (3.5 for example) to each one.&nbsp;</div><div><br></div><div>For the smaller one calculate R1 which is just the sum of the rankings. Then calculate Us which is R1 - \(\frac{n1(n1+1)}{2}\) or the total ranking it all of the values from the one sample were at the beginning.&nbsp;</div><div><br></div><div>We then compare this to the empircal distribution of all possible ranking values, the permutations. For large samples this goes normal.&nbsp;</div></div></div>
How to calculate genearlized sample variance?	Determinant of covariance matrix
What is the multivariate version of anova?	This is called MANOVA and you get the Wilks lambda statistic out of it.
How does Mesos work?	You have command nodes and worker nodes and the whole point of mesos is to manage resources and how to distribute the docker containers. The way you define everything around how and where to run the docker container is in a json - define what ports are open, how many of these containers, which docker image, etc.
What is a pod in k8?	This is the base unit of deployment - defined by an ip address. A pod can have multiple containers, that do something together.&nbsp;
What is a deployment in k8?	Says how many of a pod you want, how many times should you restart it, etc.
What are requests and limits in k8?	For requests you say I need this number of cpus or ram minimum and limit would be max
Why spark?	1. Need for constistent api for doing big data stuff<div>2. Need for a computation engine on top of different storage systems - this is in contrast to Hadoop MapReduce which was tied very closely to Hadoop file system</div><div>3. Libraries for different applications</div><div>4. Ran into hard limits for compute time, so everything started going parallel and thus why Spark went popular as well</div>
What is YARN?	This is Sparks native cluster manager - manages resources and grants resources to our application when we submit to YARN<div><br></div><div>Talks to the executor and the driver</div>
Whats a driver process and an executor process in Spark?	The driver process runs the main() function, maintains information about the application, responds to users input or program, and distributes and scheduls work on the executors.<div><br></div><div>The executor is simple there to run the code its given and to report back about how its going.</div>
What happens when you write pySpark code?	It translates it to Spark code that can be run on a JVM
When calculating confidence intervals how do we know when to use the normal distribution or the t-distribution critical value? (1.96 for normal)	So if we don't know the standard deviation (if we are estimating if) then we use the t-distribution.&nbsp; This is helping us account for the uncertainty in our estimate of the standard deviation (has nothing to do with the CLT). If we were to use 1.96 with a small sample size and estimated standard deviation, our confidence interval will be too small. The t-distribution will correct for that by giving us a critical value of 2.25 or something for example.&nbsp;<div><br></div><div>In practice though if our sample size is large enough, 1.96 might be fine to use because its a decent estimate of the standard deviation since the t-distribution is approximating the normal</div>
What is the law of large numbers?	This says that in the long run, our sample average will approximate the exected value of the random variable.
What is the matrix profile of a time series?	Given some subsequence size this will take the eucliedean distance between that reference subsequence and a sliding window of all other same size sequences. It then will shift eh reference subsequence one over, until we get to the end of the time series.<div><br></div><div>The min difference is saved for each reference subsequence giving us a vector of min differences. A small value for a reference sequence implies that there is another sequence in the time series that is close to that pattern. A large value potentially indicates an anomoly, since there aren't any other sequences with that pattern in the time series.</div>
What is an ACF plot?	On the x axis you have time lag and the y axis you have correlation. So for 1 time lag you take the correlation of the time series and the time series 1 lag behind, then do that for 2 lag, etc.
What is a PACF plot?	This looks at the correlation between the current time point and lag of k where the relationships of the intervening time points are removed. Use this to determine the AR order by choosing the lag where the PACF is first 0, since this implies that everything before that lag as a direct realtionship with the current time step, anything after that would just be carried on correlation and would add noise to the model.
What is an ARIMA model?	AR is auto regressive (regressiong on lags)<div>I is in integrated (differencing)</div><div>MA is moving average on the residuals (corrects future forecasts based on errors of recent forecasts)</div><div><br></div><div>Once differenced we can fit an ARMA model.</div>
What is a non-stationary time series?	This is a time series whose mean and variance change over time.
What does differencing do in a time series?	This creates a new time series by subtracting each subsequent point. Its easiest to think of seasonal differincing where you are subtracting last years value which would leave you with the effect not do to the seasonal change.&nbsp;<div><br></div><div>Immediate differencing would remove the effect of the mean changing and give you the signal that is occuring NOT because of the mean</div>
Whats a narrow transformation vs a wide transformation in Spark?	Narrow transformation is when you have a 1-1 mapping between input partition and output partition - your operation works just fine on one partition at a time. This happens in memory.<div><br></div><div>Wide transformation is where an input partition might output to multiple output partitions. This happens on disk</div>
When/how do we deal with an imbalanced dataset?&nbsp;	This comes up typically when we are trying to model a rare event (fraudulent transactions for example). The real problem is that typically the loss function being used is maximizing accuracy, whereas we really want to maximize recall.<div><br></div><div>One way to fix this would be to change that loss function to severly penalize the model when we are wrong on that minority class. OR we balance the dataset which will give either less weight to the majority class or more weight to the minority (kind of another way of doing the cost function change). We would want to keep our validation set unbalanced however since this is what we would see in the wild.</div><div><br></div><div>So really we can say an imbalanced problems is really the following three problems:</div><div>1. Optimizing the wrong thing (predicting all zeros is actually a good idea when going for accuracy)</div><div>2. Train set doesn't look like test set</div><div>3. To few minority classes, means you just need more data.</div>
How do we set the threshold for binary predictions?	This is problem dependent and what you are trying to optimize. What you can do is calculate the precision, recall, accuracy, F1, whatever it is as you vary the threshold and choose the max.
In spark, why have lazy evaluation?	This helps optimize the commands. For example, if the last command is to select one row, then perhaps it would have been better to select that one row first and then do all of the operations on it.
What would OOM mean in a spark job?	This would be referring to running out of memory on a specific executor.
How can you compare two time series?	Fit a model to it (ARIMA for example) and do a statistical test on the parameters. You could also do Granger causality, compare fourier coefficients, etc.
How does granger causality work?	This regresses values from a time series y with its lag variables AND the lag variables from another time series x. If there is at least one x that is significant in the regression AND still adds to the overall significance (F test) then we say X granger causes Y
What is the highest posterior density region?	All values in interval are higher than those outside it
What are the parameters of the posterior beta when binomial likelihood&nbsp;	A &nbsp;= a+sum yi<div>B = n - sum yi + b</div>
What is exchangeability?	any permutation of the random variables gives us the same joint distribution. This assumption allows us to assume the sample is conditionally independrnt
What is the likelihood principle&nbsp;	says you should get the same inference with the same data
What’s bayesian invariance?	when finding distribution of g(x) we have to do a change of variables. An alternative is to do Monte Carlo on x and then do g(x) on each draw and plot distribution
What is rejection sampling?	Pick an envelope distribution<div>Calculate g(theta)/w(theta) and if ruing is less than then we accept the draw</div>
What is Gibbs sampling?	when you find the conditionals of each parameter and then take a draw for parameter 1, use that in the conditional of 2, draw for parameter 2 and so forth&nbsp;
What does Monte Carlo integration mean?	<div>a Monte Carlo estimate essentially uses the Law of Large Numbers to approximate an expectation by taking a simple average. If we take random draws from some distribution and average over some function then it is the expected value of that function with respect to random variables distribution. When we use indicators we are really getting at a probability</div>
How do I know if my model is good?	Bic, dic (ic has a penalty for complexity) bayes factors are for comparing models so I could do a dumb model and see if the hierarchical one does better.&nbsp;<div><br></div><div>Could do a validation test on the posterior predictive but also could do a Bayesian chi square goodness of fit test</div>
What are some common conjugate pairs?	Beta binomial<div>Gamma poison&nbsp;</div><div>Gamma exponential</div><div>Normal normal with fixed variance</div>
What is the se of the bootstrap?	1/b-1 sum ( thetai - average thetas )^2
What is a bayes predictive distribution?	<div><br>{{11 1 0.png}}<div><br></div><div>As you'll notice this is an expectation with respect to the posterior so we can do a monte carlo estimation by considering different values of y_i^tilde and averaging over our posterior draws. For example, if our likelihood is normal then we can take dnorm in R for a sequence of numbers and for each number average dnorm over all draws</div></div>
What is importance sampling and how is it derived?	The need for importance sampling arises when we want to get the expectation of the posterior. The posterior is made up of a numerator and a denominator. The denominator is an integral and therefore a constant. In both the numerator and the denominator we multiply by&nbsp; I(\theta)/I(\theta) where I(\theta) is some distribution that is easy to sample from. We then use monte carlo integration for both numerator and denominator where the draws are coming from I(\theta)
What are the weaknesses of importance sampling?	1. You don't get draws from posterior, just an expectation&nbsp;<div>2. Need to make sure I(\theta) mirrors the posterior and preserves the parameter space</div>
What is the WAIC?	This is the widely available information criterion. This is made up of -2*(lppd + effective number of parameters). lppd is the likelihood posterior predictive density which is calculated by taking each data point and averaging the likelihood at that data point over all the parameter draws and then summing that up over all data points. The effective number of parameters is calculated as the variance of the likelihood at each data point where the variance is over all of the draws and then summed up over all data points.&nbsp;<div><br></div><div>This formulation has an advantage over AIC and DIC because its using all of the posterior distribution to make these calculations.</div>
What are some of the issues with MCMC?	<div><div>1 mixing meaning do we explore the space enough. Autocorrelation between draws<div><br></div><div>2. Burn in did the algorithm converge. Check this with a convergence plot and acceptance rate. Somehere between .15 and .5</div><div><br></div><div><br></div></div></div>
What is the metropolis Hastings algorithm?	"<div><div style=""text-align:left"">Let f(x) be a function that is proportional to the density of interest P(x). (In the Bayes case, f(x) would be the numerator), something that we can evaluate.)</div><div style=""text-align:left"">1. Start with y1.&nbsp;</div><div style=""text-align:left"">2. Generate a proposal, y2, from a symetric proposal density centered around y1, such as the normal. <br>3. Compute ratio f(y2)/f(y1). Draw from u~Unif(0,1). If u &lt; ratio then accept and set y1 to y2, otherwise reject and set y1 to y1.&nbsp;</div><div><br></div><div style=""text-align:left"">Metropolis Hastings does not have a symmetric distribution&nbsp;<br></div></div><div style=""text-align:left""><br></div><div style=""text-align:left"">We are trying to get at a Markov chain stationary distribution which is a probability distribution that remains unchanged throghout the chain as time progresses. If P is our transition matrix then pi = pi P refers to the stationary distribution pi. (<span style=""text-align: center;"">long run proportion of time that the chain spends in state j)</span></div>"
What is the original formula for variance?	E(X-E(X))^2
What is the general formula for the covariance between X and Y?	E((X-E(X))(Y-E(Y)) = E(XY) - E(X)E(Y)
If X and Y are independent what is there covariance?	0
If X and Y have a 0 covariance are the dependent or independent?	They could be indepenedent but not necessarily.
What does regression towards the mean refer to?	This is the phenomenon that if you are extreme for one sample, the next time you won't be as extreme, you will regress towards the mean. Take a test 1 day and do well, the same test second day maybe not as well because of the element of luck involved
How would you describe covariance?	A measure of how two variables vary together. If greater values correspond with greater values than covariance is positive, opposite than it is negative.&nbsp;
How is correlation defined?	<div>cov(X,Y)/sigma_x*sigma_y. This normalizes the covariance to be between -1 and 1 so that we can make apples to apples comparisons.</div>
What is the permutation definition?	n!/(n-k)!
What is the combination definition?	n!/k!(n-k)!
What is Bayes formula?	Given a partition of the sample space A_i then we have:<div><br></div><div>P(A_i|B) = P(B|A_i)P(A_i)/P(B)</div><div><br></div><div>where P(B) can be written as sum_j_N of P(B|A_j)P(A_j)</div>
What is one key difference between Bayesian and frequentist statistics?	Frequentist treats the parameters as unknown but fixed while Bayes treates them as unknown but a random variable.
What is conditional independence?	same as independence but with conditions. Does not imply independence or vice versa
What to do when finding expected value of rv when there is a conditioned event?	treat the event as having happens and add it to the rv expected variable&nbsp;
What is a sampling space?	<div>Set of all possible outcomes or results of experiment. For example, with a coin the sample space would be {H,T}. Note that we can define a sample space in different ways. For two coins we could write {0,1,2} representing the number of heads or we could write {HH, HT, TH, TT} which is a more detailed way of writing the sample space.</div>
What is an event?	<div>A subset of the sample space. In a two coin example the sample space might be {HH, TH, HT, TT} and an event might be {HH, TH}, the event that the second coin is heads.</div>
What is a trial vs. experiment?	A trial is a simple experiment. To avoid confusion the experiment is referring to the multiple trials.
What is a random variable?	A random variable is neither random, nor a variable. It is a function that takes in simple events from a sample space and assigns a real number. So the domain is the sample space and the range is the real numbers.
What properties must a pmf satisfy?	All of the probabilities must be greater than 0 and all must add up to 1.
What is the expected value of a discrete rv? What is the expected value of a crv? What is the expected value of a rv conditioned on an event?	"<img src=""18 3 2.png""><div><br></div><div><br></div><img src=""18 3 0.png""><div><img src=""18 3 1.png""><br></div>"
Whats the transformation formula for a discrete random variable Y=g(X)?	"<img src=""19 1 0.png"">"
What are the properties of the indicator random variable?	Helps us to count - we use it when we are determining if the event A happend or not.&nbsp; E(I_A) = P(A)&nbsp;
What is a probability function of a random variable?	"<div>This is written as: f(x) = P({sigma_k \in S|X(sigma_k)=x}) or the probability of the combined simple events that give us X=x. With continuous rv's this is a little tricky because prob. of a point is 0 so a good way to define it is by f(t)</div>{{21 0 0.png}}<img src=""21 0 0.png"">"
What is the law of the unconscious statistician?	"The expected value of a function of a random variable is with respect to the pdf of the random variable.<div><br></div><div><br></div><img src=""22 1 0.png""><br>"
<div>What is the probability integral transform and give a proof of it?</div>	"<div>The probability integral transform says that for any cdf function F, if we set Y=F(X) then Y is uniformly distributed.</div><div><br></div><div><img src=""23 0 0.png""><br></div><div><br></div><div style=""text-align: left;"">This also implies that if you put the original random variable into its own CDF it is uniformly distributed (this is because Y=F(X) where X is the random variable vs. F(x)).&nbsp;</div><div style=""text-align: left;""><br></div><div style=""text-align: left;"">This also implies that if Y ~ Uni(0,1), then F^-1(Y) has X's cdf.</div>"
What is the definition of the CF and what properties must a CDF satisfy?	"<div>F_x(x) = P(X &lt;= x).&nbsp; As x goes to -infinity then the cdf goes to 0, as x goes to infinity the cdf goes to 1. Must be non decreasing. Must be right continous.&nbsp;</div><div><br></div><div><br></div><img src=""24 1 0.png""><br>"
How do you transform a function to a probability density function?	Divide by its integral (since the integral is a number we pull it out of the other integral to give us a normalizing constant that gives 1)
What is the support of a distribution?	The set of values x where f(x)&gt;0
What is the derivative of the cdf?	F'(x) = f(x)
<div>What is the one dimensional transformation? Where does it come from?</div>	"<div><img src=""28 1 0.png""><br></div><div><br></div><div>This comes from the cdf first and thinking about the support of Y and then taking the derivative of the cdf Y.</div><div><br></div><div>Make sure to find what the support of Y is first</div><div><br></div><div><br></div>"
How do you do the transformation of a nonmonotonic function?	Split up the space into areas where g(X) is monotonic and then do the transformation process on each section. Then sum it all up.
How is the n^th moment defined? How is the nth central moment defined?	E[X^n], E[X - E[X]]^n
What is the moment generating function?	<div><div>M_x(t) = E(e^{tX}) if it exists for all t in some open interval containing 0.</div></div><div><br></div><div>The MGF uniquely determines a distribution.</div>
What is a location/scale family?	These are distributions that we can shift and scale. With the normal distribution we can subtract the mean and scale by the standard deviation to get the standard normal distribution.
What does Hybrid bayes rule look like?	"<img src=""33 1 0.png"">{{33 1 0.png}}"
PDF of exponential, expectation, and properties?	"<img src=""34 2 1.png""><div><br></div><div>Lambda is the rate parameter. The expectation is 1/lambda.&nbsp;</div><div><br></div><div>Story: waiting time for a shooting star. You know that this is a memoryless process (just because you waited a long time doesn't mean the star is more likely to appear). Say you know on average a star appears every 15 minutes. Then we can model the waiting time as Expo(4)</div><div><br></div><div>Rescale:&nbsp;</div><div><br></div><div><img src=""34 2 0.png""><img src=""34 2 2.png""><br></div><div><br></div><div>Min and Max</div><div><br></div><br>"
What does memorylessness mean?	"<div><img src=""35 1 0.png"">Whats happened in the pass has no affect on the future (just because I've waited t time for a shooting star doesn't make it more likely to come)</div><div><br></div><div><br></div>{{35 1 0.png}}"
When taking the marginal of a joint distribution how do we know what the bounds are?	If we are integrating out y for example then our integral will be with respect to y but the bounds will be in terms of x.
What is the uniqueness property of the MGF?	Two random variables X and Y are distributed the same iff they have the same MGF
What is the MGF of the sum of two independent random variables?	The product of the MGF of the seperate variables.
What does the joint cdf of X,Y look like?	"<div><img src=""39 1 0.png"">{{39 1 0.png}}</div><div><br></div><div>= integral from -\infty to x of integral from -\infty to y of f_xy(s,t) dt ds where s is the dummy variable for x and t is the dummy variable for y</div>"
How is the marginal distribution defined from a joint probability?	"<div><div><img src=""40 1 0.png""></div><div>Don't forget that the support could be different implying that the bounds of the integral could be different</div></div><div><br></div><div>Whe doing the discrete version think of it for a particular X and then sum all of Y for that particular X.</div><div><br></div><div>The joint pmf cannot be determined from just the marginals.</div>"
What is the definition of conditional expectation E[y|x]?	E[y|x] = \int y f(y|x)
If X and Y are independent what do we know about the MGF of X+Y and expected value of E[g(X)h(X)]?	MGF of X+Y will be product of the separate MGFs and the expected value will be multiplied together. Extends to n mutually independent rvs.
How do we know if two r.v.s are independent?	<div><div>If their joint cdf, pdf can be written as the product of their marginals or if the conditional of one is its marginal. This extends to n random variables as well. This can be relaxed to finding just general functions g and h such that f(x,y)=g(x)h(y) for x and y</div></div>
How do you get moments from the moment generating function?	<div>Take the nth derivative with respect to t and set t to 0. This assumes we can differentiate within the integral.&nbsp;</div>
What is the bivariate discrete transform?	"<div><div>sum over (x,y) element of A_uv of f_xy(x,y) where A_uv are all (X,Y) such that g_1(x,y)=u and g_2(x,y)=v. g_1 and g_2 are the transform functions. Don't forget to deal with the support.</div></div><div><br></div><div><br></div><img src=""45 0 0.png""><br>"
What is the table of counting look like?	"<img src=""46 2 1.png""><div style=""text-align:left""></div>"
What does the continous bivariate transformation look like?	"<img src=""47 1 0.png"">{{47 1 0.png}}<div>This assumes that the transformation is subjective.</div>"
What does the joint pdf of continous random variables look like in relation to the joint cdf?	"<img src=""48 0 0.png"">{{48 0 0.png}}"
How do we get any normal random variable to be N(0,1)?	Subtract its mean and divide by its standard deviation.
What are the discrete distributions for when we have the four combos of fixed # of trials with replacement and without replacement and draws until r^th success with replacement and without replacement?	"<img src=""50 0 0.png"">{{50 0 0.png}}"
What is the significance of the Gamma distribution or a story to fit it? What is its pdf and expectation?	"The gamma distribution is related to the exponential distribution in that the waiting time for an event is Exp(lambda) and the waiting time for the n^th event is Gamma(n,lambda).<div><br></div><div>Example: You are at a bank in line with 3 people ahead of you. The serving time for each person is exponential with an average waiting time of 2 minutes. What is the distribution of YOUR waiting time?</div><div><br></div><div>Gamma(3, 1/2)</div><div><br></div><div><br></div><div><img src=""51 1 0.png""><br></div>"
What is the normal distribution?	"<img src=""52 0 0.png"">"
What is the convolution formula and what does it look like?	"<div><div>We want to know the pdf of X+Y so we let Z=X+Y and W=X. Using the bivariate transformation we get (since the determinant of the Jacobian is 1):</div><div><br></div><div><img src=""53 0 0.png""><br></div><div><br></div><div><br></div><div>We then integrate over W to get at the pdf of X+Y</div></div><div><br></div><div>Note that it is important to get the bounds of W correct. It can sometimes be dependent on Z.</div>"
What is the formula for the variance of a sum?	<div><div>Var(X_1+X_2+X_3...) = sum(Var(X_i)) + 2* sum(i&lt;j)Cov(X_i,X_j)<br></div><div><br></div><div>If the variables are identically distributed we have n(Var(X_1)) + 2 *nC2*Cov(X_1,X_2). We have n choose 2 because we are sampling without replacement and order does not matter.</div><div><br></div><div>when there are only two variables this simplifies to:</div><div><br></div><div>Var(X+Y) = Var(X) + Var(Y) + 2Cov(X,Y)</div></div><div><br></div><div>If X and Y are independent then we drop the 2Cov(X,Y) term</div>
<div>What is Cov(a + X, b+Y) and Cov(aX,bY) where a and b are constants? What is Cov(W+X, Y+Z) where all variables are RVs? What is Corr(aX + b, cY + d)?</div>	"<ol><li style=""text-align: left;"">Cov(X,Y)</li><li style=""text-align: left;"">abCov(X,Y)</li><li style=""text-align: left;"">Cov(WY) + Cov(WZ) + Cov(XY) + Cov(XZ)<br></li><li style=""text-align: left;"">Corr(X,Y) - it apears that correlation is location and scale invariant whereas Covariance is just location invariant.</li></ol>"
What is the pdf of the uniform distribution? What is the expected value?	1/(b-a), 1/2(b+a)
What is the posterior of a Beta/Binomial Bayes setup? What is the expected value of the Beta distribution?	"<div><img src=""57 2 0.png""><br><div><br></div></div><img src=""57 2 1.png""><br>"
Whats the story around the Chi-square distribution? What distributions is it related to?	"<div><img src=""58 0 0.png""><br></div><div><br></div><div>Chi square is also distributed Gamma(n/2, 1/2).</div>"
<div>What is the negative binomial story, its distribution and expectation?</div>	"This is the number of failures we have before we achieve our rth success.&nbsp;<div><br></div><div><br></div><img src=""59 0 0.png""><br>"
<div>When do we use the hypergeometric distribution? What is its pmf and expectation?</div>	<div><div>This is the same as the binomial but without replacement which implies our probability changes with each successive draw.&nbsp;</div><div><br></div><div>KCk * (N-K)C(n-k)/NCn</div></div><div><br></div><div>N is the population size</div><div>K is number of success states in pop.</div><div>n is number of draws</div><div>k is number of observed successes</div><div><br></div><div>The mean is nK/N</div>
What is the poisson story, pmf, expected value, variance?	"<div>Low probability event that occurs in many ways at an average rate of lambda during a given time period or spatial unit. The Poisson is the number of times that event occurs in that unit.</div><div><br></div><div><img src=""61 1 0.png""><br></div><div><br></div><div>Expectation and variance are lambda</div>"
What are some common biohazards when doing probability?	"<ol><li style=""text-align: left;"">Abusing the naive definition of probability. This can only be applied when all outcomes are equally likely.</li><li style=""text-align: left;"">When dealing with conditional P(A|B) and P(B) remember that P(B) is not 1 its the <i>prior</i>&nbsp;probability.</li><li style=""text-align: left;"">Don't assume independence without justification (binomial vs. hypergeometric)</li><li style=""text-align: left;"">Do sanity checks - pdf integrates to 1, variance above 0, probability between 0 and 1, supports make sense.</li><li style=""text-align: left;"">Don't confuse rv's, number and events: X, g(X) are rv's, P(X&lt;x), E(X), Var(X) is a number, X=2 is an event, F(X)&gt;=1 is an event. It doesn't make sense to take the integral of a random variable (just its pdf). Doesn't make sense to write P(X) since X is not an event.&nbsp;</li></ol>"
What is a stochastic process?	"Simply a collection of random variables where each random variable is associated with a unique index. The index might be the natural numbers for example associated with time. An outcome of a stochastic process is a ""sample function"" or a ""realization"".&nbsp;&nbsp;<div><br></div><div>The best way for me to understand this is to think of Gaussian process functions. Each point in time is represented by a random variable and a stochastic process is a collection of all those variables. Therefore a realization of the process is a function because it is a realization of multiple random variables. (Meaning the index set is on the x-axis for example?)</div>"
What is the poisson process?&nbsp;	A stochastic process so a collection of poisson random variables that have the distinction that each interval in the state space is independent of everyother interval.
What is the categorical distribution?	This models the probability of getting a certain category out of k categories. Its analogous to the bernoulli distribution but instead of having 2 categories we have k.&nbsp;<div><br></div><div>The support is therefore {1,...,k}. The pmf is just p_i for each category with the sum of the p_i's equal to 1.</div>
What is the multinomial distribution?	"<div>The multinomial distribution is a generalization of the bernoulli, binomial, and categorical distributions all rolled into one.<div><br></div><div>I think the best way to describe it is analogous to the bernoulli/binomial relationship. The multinomial is simple the categorical distribution repeated over n trials. Therefore the support is all possible combinations of distributing n trials over k categories.&nbsp;</div><div><br></div><div>The way we say this is that a vector X = (X_1, X_2, ...X_k) follows a multinomial distribution. Each element of the vector will be a count for that particular category.</div><div><br></div>pmf =&nbsp;</div><div><br></div><div><img src=""66 2 0.png""><br></div><div><br><div>support =&nbsp;</div><br></div><div><img src=""66 2 1.png""><br></div><div><br></div><div>Where each p_i is the probability of getting in that category.</div><div><br></div><div>The pmf is found by thinking of taking each trial and thinking about where to put it in a category. The probability of getting the vector (X_1,X_2,...X_k) is therefore p_1^x_1 p_2^x_2, etc. but that can be arranged in multiple ways so therefore the multinomial coefficient.</div>"
What is Simpson's Paradox?	<div>This is saying that if we ignore confounding effects and just group everything together, we can get one conclusion. However, if we break up into groups to account for the confounding variable we can see a reversal in the conclusion.</div><div><br></div><div>This occurs for two reasons: the groups (split by confounding variable) are of different sizes. Secondly the performance of the confounding variable level is different. So if one treatment has most of its examples from the better level of the confounding variable it will mask the true effect when combined&nbsp;</div>
What does the multivariate distribution look like?	"<img src=""68 0 0.png"">{{68 0 0.png}}"
What is Adam's law or law of total expectation? Whats the proof?	"E[X] = E_Y(E_X[X|Y])<div><br></div><div>Y is number of eggs and X is number of surviving eggs. If Y is poission and X|Y is Binomial then we have for the inner expectation yp and outer is plambda</div><div><br></div><div>Heres the proof:</div><div><br></div><img src=""69 0 0.png""><br>"
<div><div>What do we use the geometric distribution for and what is its pmf and expectation? What is the variance? What is the first success distribution and expectation? How do you calculate expectation for this distribution?</div></div>	"<div><div><div>This is the same as the negative binomial but where we count the number of failures before the first success.<div><br></div><div><img src=""70 0 0.png""><br></div>{{70 0 0.png}}</div><div>q/p^2 is the variance</div></div><div><br></div><div>If you want to count the first success then the pmf is q^(k-1)p and the expectation is 1/p.</div></div><div><br></div><div>To find the expectation write it out as an infinite sum and then divide by the common ratio.&nbsp; Call this S/p. Take the original infinite series and subtract S/p from it. It will then turn into a geometric series.&nbsp;</div>"
front	back
How does the internet work in general?	the main idea is that the internet was designed to be completely decentralized. TCP is the protocol that says how to send information. The info is split up into packets which are sent one at a time through the network in the most optimal route&nbsp;
What is declaritive style?	You explicitly give directions in your code to accomplish the task
What is imperative style?	You give an adderss for example vs. specific directions to get there. In others words you code what you want vs. how you want it.
What is a computer kernel?	This is a computer program that is at the core of a computer's operating system and has complete control over everything in the system. It connects application software to the hardware of the computer.
What is a docker image and docker container?	An image is a prebuilt bunch of layered instructions that is portable between computers. These instructions say what operating system we will work in and what applications to automatically downloaded when the image is activated (?). A container puts another layer ontop of this image and all manipulation doesn't go below this container layer. Therefore we can have various containers working on the same image and all have different states.&nbsp;
What is HTTP?	Hypertext Transfer Protocol is designed to enable communications between clients and servers. Python's requests package uses this when hitting api's.
What is a URI?	This stands for Uniform Resource Identifier - a string of characters that unambiguously identifies a particular resource. URL is the most typical form.&nbsp;
In the REST framework what does resource mean?	This is the thing that the client is asking for or is potentially updating (webpage, webform, etc.)
What is a daemon?	A computer program that runs as a background process rather than being under the direct control of an interactive user.&nbsp;
What is a computer process and what are its 3 basic components?	A process is an instance of a computer program that is being executed. Components are:<div>1. Executable program</div><div>2. Data needed in program</div><div>3. Execution context of the program (state of process).</div>
Whats a Dockerfile?	"This is the file that generates a new docker image that containers can run on. The first line is typically ""FROM"" giving the path to the base docker image (kind of like inheritance?)"
What is apt-get?	This is like pip for python - just a way of downloading packages in linux using the dpkg packaging system.
What is a web server?	This coan mean hardware or software - if talking about software its the code that directs traffic essentially.
What is a cache?	This is a memory storage technique that stores a small amount of information but that is easier to access more quickly. In web scenario a cache is putting that websites data on your computer so the next time you look at that website it loads much quicker. CPU cache is referring a type of RAM that allows easy access. So this is where we would story stuff that we are going to reuse over and over.
What is the heap?	This is a region of your computer's memory that is not managed automatically but gives access to global variables.&nbsp;
What is the stack?	A special region on the computer's memory that stores temporary variables created by each function. Memory is managed automatically. Stack variables are local in natures.
What is a thread?	<div>Threads are contained with processess. A thread is an independent set of values for the processor registers (in the book example it is the page and word you are going to come back to later). A processor can switch between threads giving the impression of multi-tasking.&nbsp;</div>
What is the CPU and what does it do?	The CPU is the brains of the computer. It fetchs data from RAM, and performs the boolean calculations, etc. A CPU can be made up of multiple cores which is effectively multiple CPU's
What is a parquet file?	<div>Stores data in a columnar format. This can make things much quicker if we are for example looking to get all rows with sales&gt;$500 - instead of reading in things row by row and then checking the sales column, we can instead read in just the sales column and find which records to keep. Because columns are spread out we can use parallelization and also compression is better.</div>
What is the difference between ENTRYPOINT and CMD in a Dockerfile?	The Entrypoint is the initial command that the Docker container will start at, CMD is anything after that.
What is batch?	Looking at all your training examples before updating parameters
What is overflow and underflow? What is an example of when this might occur?	Overflow happens when the computer approximates the extremely large number as infinity. Underflow happens when the computer treats the value as 0. The softmax output could have an issue because of the exponents in the numerator and denominator.
<div>What is conditioning? What is a condition number of a matrix?</div>	<div>Conditioning is how rapidly a function changes with respect to small changes in input.</div><div><br></div><div>If it has an eigenvalue decomposition this is the largest eigenvalue divided by the smallest eigenvalue. When this number is large, inverting the matrix will be sensitive to error in the input for the equation f(x) = A^{-1}x</div>
What is an epoch?	<div>Means one pass over all training data. Could be from minibatch or batch - the batches refer to when you update the parameters</div>
Why does gradient descent work or where does it come from?	"First of all we can think of the derivative in this light:<div><br></div><div><img src=""4 2 1.png""><br></div><div>(think of this as the slope-intercept form giving us an approximation)</div><div><br></div><div style=""text-align: left;"">This relation is useful because it helps us see how to change x in order to change y.</div><div>&nbsp;</div><div><img src=""4 2 0.png""><br></div><div>is less than f(x) (think of a parabola). Therefore we want to move x in the direction of the negative gradient.</div>"
What is the directional derivative?	<div><div>How f is changing in the direction of the unit vector u. It can be written as u' times gradient</div></div>
What is the Jacobian?	This is when our function is R^m to R^n (gradient is R^n to R)<div><br></div><div>The rows will vary on the output (n output) and the columns will vary on the partial derivatives (m inputs)</div><div><br></div><div>For example the first row of the matrix would be...</div><div>[df_1/dx_1, f_1/dx_2, ...]</div><div><br></div><div><br></div>
What is the Hessian matrix?	<div>This is the matrix of partial derivatives of a function from R^n to R<div><br></div><div>Row 1 would be df/dx1dx1, df/dx1dx2, ...</div></div><div><br></div><div>We can also think of the Hessian as the Jacobian of the gradient.</div><div><br></div>
What do second order derivatives measure?	The curvature of a function. Sometimes the gradient (think of parabolas) doesn't do as well in picking the next place to go in the function because the slope is changing quickly, so the second derivatve can correct for that.
How do we represent the second derivative in a certain direction?	d'Hd where d is a unit vector and H is the Hessian
What is the relationship between the Hessian and eigenvectors?	If the Hessian is real and symmetric we can do a eigenvector decomposition. The second derivative in the direction d is given by d'Hd. If d is an eigenvector of H then the second derivative is the eigenvalue associated with that d. For other direction d the second derivative is a weighted combination of the other eigenvalues.
What is a Talyor series approximation and how is the second order defined?	"<div><img src=""11 0 0.png""><br></div><div>This is the best approximation of the function using the second order where f(x) has multiple inputs and one output.</div>"
What happens to the Taylor series when doing gradient descent and how can we interpret it?	"Recall that the best direction to go in for decreasing the function is the negative of the gradient so we go x_0 - eg<br><div><br></div><div><img src=""12 1 0.png""><br></div><div><br></div><div>The first term is where we start, the second term is how much we go down by and the third time is the correction because of the curvature.</div>"
What is the second derivative test in one dimensions?	This tells us how the derivative is changing. It is used at a critical point when f'=0.&nbsp; If f''&gt;0 this means that as x increases the derivative or slope increases and when x decreases the slope is coming into the critical point, meaning we are at a local minimum.
What is the gradient?	<div><div><div><div><div><div><div><div><div>A vector of partial derivatives for each element of the vector. The partial of x_i tells us how the function changes as we increase x_i at vec(x). Think of lim as h--&gt;0 of [f(x_i + h, x_{i+1}, ..) = f(x_i, x_{i+1}, ...)]/h. I'm not really sure how to interpret the gradient itself - it seems to only make sense when we multiply it by a vector almost like a tool we can use. It is a function - only has values when we plug in a point which is what the derivative is anyways - a function so the same thing as one dimension. The weird part though is unlike one dimension where the derivative at a point is the slope at that point, the gradient at a point is a mixture of slopes I guess? We can prove though however that the gradient at a point points in the direction of steepest ascent.</div></div></div></div></div></div></div></div></div>
What does the second derivative test look like in multiple dimensions?	<div><div>Recall that d'Hd gives the second order derivative and that the derivative is made up of a combination of the eigenvalues of H. Therefore if H is positive definite this implies the eigenvalues are all positive and the second derivatives are all positive implying we are at a local minimum.</div><div><br></div><div>If the condition number of the Hessian is high this implies the max eigenvalue is much higher than the min eigenvalue implying the derivative is changing quickly in one but slowly in another so gradient descent performs poorly.</div></div><div><br></div><div>The reason it performs poorly is because gradient descent is not aware that the derivative is increasing more quickly in one direction (its starting to descend less) so it should prefer the other direction where the gradient is not increasing as much and is descending more.</div>
What is the vanishing gradient problem or saturated gradients?	This is when our input to the activation function gets so big or so small that it leads to small derivatives from the activation function which barely changes the weights in the update equation.&nbsp;
How to fix the vanishing gradient problem?	Use Relus since they don't have a small gradient.
List some activation functions and their properties	<div>Identity (x, all reals, doesn't allow for complex functions), Sigmoid (1/(1 + e^-x), range 0-1, vanishing gradient problem), TanH(like sigmoid, range 0-1, vanishing gradient problem), ReLu (0 for x&lt;=0, x for x&gt;0, positive reals, forces negatives to be 0 which might not be good/dead neurons), Leaky ReLu (0.01x for x&lt;0 and x for x&gt;=0, hopefully fixes the dead neuron problem), softmax(e^z_i/sum e^z_i, where z_i is an element of the input vector, range 0-1, good for probabilities).</div>
<div>What is stochastic gradient descent?</div>	<div>Take a random subset of the training data, find the change in the parameters, and update. The idea is that our cost function is averaging over the loss of each training data example and it can take awhile to find the loss of each example. Using a random subset (and calling it minibatch) the thought is the average loss of the minibatch will be approximate to the average loss of all training examples.</div><div><br></div><div>Also stochastic gradient descent has a natural regularization effect, by doing updates on random instances we are less likely to get stuck in a local minimum.</div>
What is a dead Relu or dead neuron?	<div>This occurs when our output of the activation function is always 0 as a result of the input always being negative (possibly because of a large negative bias). This is a problem because then that neuron can no longer discriminate between examples.&nbsp;</div>
What is the partial derivative of the cost function intuitively telling us?	How fast the cost function is changing as we change that weight.
What is the goal of backprop?	<div>To compute the partial derivatives of the cost funtion with respect to any weight or bias. These partial derivatives make up the gradient evaluated at the current location (meaning at the current values of the weights and biases) which can be subtracted from the current location to get the next best step.</div>
What is the Kullback-Leibler divergence measure?	"<div><div>It is a measure of how different two distributions are. It is the expectation of the log difference between the two distributions with respect to one distribution.&nbsp;</div><div><br></div></div><div><img src=""23 1 0.png""><br></div><div><br></div><div>By weighting with the distribution we are saying we don't care as much about the differences that are less likely to happen.<br><div><br></div><br></div>"
Why use an activation function?	One reason might be to introduce nonlinearities - but the other reason is to allow more smooth behaviour - we don't want our output of a neuron to suddenly completely flip from 0 to 1 because of a minor change.
When doing classification why use the MSE vs. directly minimizing missclassification?	This gives us a smoother function that helps us to see best how to change the weights and biases.
Why is backprop so fast? What is an intuitive way of explaining it?	It allows us to do just one forward and backward pass. It is a quick way of finding the partial derivatives but it also has this added intuitive interpretation of passing backwards the error calculated at the very end.
<div><div>What is minibatch? Why do mini batch? What is online learning?</div></div>	<div><div>Looking at a subset of training data before updating parameters. This means you would update your parameters around n/b times if n is the number of training examples and b is the minibatch size.</div><div><br></div><div>One reason to do minibatch is that it could possibly genearlize better because the gradient is bouncing all over and so we are more likely to not get stuck in local mins etc.</div></div><div><br></div><div>Online learning updates after every training example.</div>
<div><div>Define cross-entropy and characteristics of it. Why was cross-entropy chosen in the first place? When should we use cross-entropy?</div></div>	"<div>Used when the output is a probability for a given classification.</div><div><br></div><div><img src=""28 1 0-52f43478f4540cb8296f8c7ae520703492c24e18.png""><br></div><div><br></div><div>Why this is useful is that it penalizes predictions for classes that are very confident but are wrong! So if its a very low probability for a given class (all other classes are zerod out) then it will be very high for that observation.</div><div><br></div>The general definition for M&gt;2 classes is given as such:<div><br></div><img src=""28 1 1.png""><br><div><ul><li style=""text-align:left"">M is the number of classes</li><li style=""text-align:left"">c is the class label</li><li style=""text-align:left"">where y is an indicator (1 if for observation o, c is the correct classification)<br></li><li style=""text-align:left"">p is the predicted probability observation o is of class c</li></ul><div style=""text-align:left"">If there are 2 classes then we can simplify it down.</div><div><br></div><div>Cross-entropy was chosen because when you calculate the partial derivatves with respect to the weights and biases what you find is a natural expression that directly relates the error to the partial derivative. Therefore a large error leads to a larger update in the gradient descent algorithm. This is intuitive to our learning because if we are extremely wrong then we want to quickly fix what we need to.</div><div><br></div><div><br></div><div>Cross-entropy should always be used, especially when the activation functions are sigmoid. This is because when we randomly select weights chances are high we will be initially very wrong and have a highly saturated neuron that doesn't update quickly because of the derivative (if we were using MSE). Using cross-entropy however we are able to more quickly improve because there is no activation function derivative in the overall partial derivative.</div><div><br></div></div>"
<div><div>What is the softmax function? What function is it trying to approximate? What cost function should we use with it?</div></div>	<div><div><div>This function goes from R^K to R^K and takes each element of the vector, exponentiates it, and divides by the sum of all elements exponentiated. It is trying to approximate the arg max function if we think of the arg max function output as a one hot vector with a one indicating the position of the max value. If we use the log likelihood cost with softmax then we get a speed up in learning.</div></div></div>
Why do neural nets not overfit worse than they do? (Lots of parameters to amount of data should imply terrible overfiting problems).	It has been conjectured that the dynamics of gradient descent learning in nets have a self-regularization effect.&nbsp;
What is dropout (how does it work) and why does it improve the network?	We set up the network we want. Then when we train we drop some percentage of the nodes for a given layer (for arguments sake say we drop half). Then we update our weights and biases using this modified network. We then replace the removed nodes and pick another random set of nodes to remove, update the weights, and so forth. When we go to apply the actual complete neural network we divide the weights by half since there will suddenly be twice as many weights going into the next layer then was originally trained for, leading to a higher activation than expected.<div><br></div><div>We can think of this as an ensembling method because we are essentially combining the results of lots of neural networks.</div><div><br></div><div>It makes sure tha tthe model is robust to the loss of any individual piece of evidence</div>
What are some regularization methods in neural networks?	<div>Early stopping (looking at a validation set and finding when the accuracy becomes saturated), increase training data (we'll still overfit on the training set but not as bad), L2 regularization (just add the l2 norm on our weights in the cost function with a regularization parameters so that our network learns smaller weights), L1, dropout, and artificially expanding the training data.</div>
How is artificial training data a regularization method?	We take images for example and rotate them and so therefore exposing them to more types of images to make the model more robust.
Why does L2 regularization work in neural nets and how to think about it? What are some other benefits of it?	<div><div>A network with small weights won't change as much with new input (similar to a linear model vs. a crazy polynomial) and therefore it might generalize better. If you had a weight that was too large but doesn't see action much it could bias the model.</div><div><br></div><div>When you do the gradient descent algorithm with the regularization term we can see that it will decrease the weights and then add the gradient, thus the name weight decay. The weights can still grow if they overcome the regularization but not as fast.&nbsp;<div><br></div><div>The other benefit to all this is more replicable results. If we don't do regularization then we get more unpredictable results depending on our training data because the weights can eventually get really large and pretty much point in the same direction and get stuck in a local minimum. By keeping them small we can explore better.</div></div></div>
What is a local receptive field from CNN's?	The region of the input image associated with the hidden neuron
Describe how CNN's work	"<div style=""text-align: left;"">1. We take the image and create whats called a local receptive field (might be 5x5 pixels for example. This might start in the top left corner for example and shift over by one pixel (might be more, called the stride length). Each shift is associated with one hidden neuron.<br>2. Each hidden neuron will have the same weights and biases. Might be an edge detector for example. We call this a feature map, meaning each feature map is defined by 5x5 shared weights and a shared bias.<br>3. Create multiple feature maps each with shared weights.</div><div style=""text-align: left;"">4. We then do a pooling layer on the convolution layer to simplify the info. Might look at a 2x2 region and take the max for example. The idea is that the max may be sufficient in describint whats going on in that region. Do this to each feature map seperately.</div><div style=""text-align: left;"">5. Might add on a output layer at the end that predicts which class.</div>"
Why does the loss function need to be an average?	<div><div><div><div>Backprop is meant to update after every training example because we are comparing the output vs a single y. We are finding the gradient at each example that is what backprop gives us. We can take the gradients of the loss function for each example and then average them which will give us the appropriate gradient of the averaged loss function. You need this if you want to do mini batch for example. That’s really the main reason&nbsp;</div></div></div></div>
What is the basic idea of tf-idf?	The tf part measures roughly how many times a term appears in a document and the idf part measures how many documents the word appears in. The two are multplied together and give a weighted combination that ranks terms higher that appear frequently in a document but not in the larger corpus.&nbsp;
How does LDA work?	"<div><img src=""1 2 1.png""><br></div><div><br></div><div><br></div><img src=""1 2 0.png""><br>"
What is the posterior we are after in LDA?	"<div><img src=""2 1 0.png""><br></div><div>If we know z then we can find out phi and theta the vectors we really care about (giving us the probability over words for each topic and giving us probabilities over topics for each document).</div><div><br></div><div>This is known as a collapsed Gibbs sampler because we integrated out phi and theta. We can't directly sample from this joint distribution so there are some tricks around that.</div>"
"What is the ""no free lunch theorem""?"	All machine learning algorithms perform equally, averaging across all problems.&nbsp;
What are the two parts of any maching learning poblem that Chis Bishop mentions in his podcast?	The data and the assumptions. Treat assumptions as a first class citizen.
Why do we use a probability distribution to represent the relationship between dependent and independent variables?	<ol><li>Only have finite variables to model the relationship</li><li>Only have a limited amount of data - don't have data for all range of dependent variable or independent variable.</li></ol>
If the more features we have the closer to a deterministic relationship why don't we necessarily want more features?	<div>We have limited data so more features could be tuned to fit the specific training data. This is related to curse of dimensionality (need more data for more variables).</div>
What is the Bayes classifier?	This is the optimal decision rule to make when we have a simple 0-1 loss function. This is the theoretical best we could do for a given distribution.
What does the Bishop Bayes classifier picture look like?	"<img src=""5 0 0.png"">{{5 0 0.png}}"
When looking at the decision theory, why do we minimize the expected loss function and not just the loss function?	The true class label and the predicted class label are random variables and so we can't calculate the loss function on variables we don't know the value of.
What is the test error or prediction error?	"<img src=""7 0 0.png"">"
What is the expected prediction error?	"This is the expected value of the prediction error&nbsp;<img src=""8 1 0.png"">"
What is the formula for bias?	"<img src=""9 1 0.png"">"
What is the formula for variance?	"<img src=""10 1 0.png"">"
Explain the bias/variance tradeoff	The bias/variance tradeoff says that the expected error of a model can be split up into a bias component and a variance component. The variance term shows how much a model varies over training sets and the bias shows how far off the model will be on average over all training sets.
What is a generative model?	Model that attempt to find the original probability distribution P(X,Y), the distribution the data were pulled from.
What is a discriminative model?	Attempt to find the posterior distribution P(Y|X)
What is the discriminative function?	A function that relates the independent variables to the dependent variables - f(X) = Y
What is the curse of dimensionality?	The more features we include the more data we need to be able to have the same performance. The amount of data we need groes exponentially.
Give an example that illustrated the curse of dimensionality&nbsp;	Start with one dimensions with equally spaced intervals (4) and a data point in each interval. Once we go to two dimensions we now need 16 data points in each box, 64 for each cube.
Visualize the classic confusion matrix and the terms right around it	"<img src=""17 1 0.png"">{{17 1 0.png}}"
What is multiclass classification?	Has more than two classes - assumes that its going to be one of the classes but can't be both or several of the classes
What is multilabel classification?	Predicting properities that are not mutually exclusive such as text documents that might talk about multiple topics (this document is over finance and politics).
What is multioutput regression?	Each data point has multiple values - such as wind direction and magnitude
What are the weaknesses of the roc curve?	It doesnt take into consideration class imbalance very well. Since you are deaing with false pos rate then you are measuing how you are doing on the negatives which might mask how you are doing on the positives.&nbsp;
Why do precision recall curve?	both are measuring how you are doing on the positives
What is the f-score?	2*precision * recall/(precision + recall)<div><br></div><div>Harmonic mean between these two</div>
What is sensitivity and specificity?	true positive rate and true negative rate&nbsp;
Pedantic	<div>excessively concerned with detail or formalism, negative conotation</div>
Preclude	Prevent from happening; make impossible
Prosaic	"<font color=""#000002"">having the style or diction of prose; lacking poetic beauty</font>"
endongenous	having an internal cause or origin
accretion	"<font color=""#000002"">the process of growth or increase, typically by the gradual accumulation of additional layers or matte</font>"
What is CI/CD?	<div>Continuous integration/continuous delivery. This is the idea that is behind DevOps. The first step, continuous integration is where developers contribute to a shared repository. This includes automated testing so things are broken. The continuous delivery part is where we automate the process where new code is deployed to target environments, such as test or staging environments. The last stage is continuous deployment which releases to production.</div>
What is DNS in the context of the internet?	DNS is the phonebook to the internet. Translates domain names to IP addresses.
What is a proxy server?	<div>a gateway between you and the internet. Everything passes through this server. Hopefully shields you from the bad things of the internet. A proxy server is basically a computer on the internet with its own IP address. It hides the clients IP address</div>
What is a reverse proxy server?	<div>When something is returned to the client it appears that it came from the proxy server</div>
What is nginx?	<ul> <li>a web server that can be used as a reverse proxy server, load balancer, mail proxy, and HTTP cache</li></ul>
What is a IP address?	<div>unique address of your computer, kind of like a street address.</div>
What is a VPN?	<div>simulates a private network over a public network by adding in encryption, authentication and integrity protection. A VPN establishes a secure connection to a VPN server. This is why you would want to use it when working over public wifi since your exposure through the web will be from the VPN server.</div>
What is a hypervisor?	<div>&nbsp;Software that is the intermediary between the physical hardware and different software such as a Virtual Machine. If we think of the hardware (CPU, memory, etc.) as resources, the hypervisor is in charge of allocating those resources between different “guests” or virtual machines.&nbsp;</div>
What is elastic search?	<div>Unstructured document store, allows for searching in unstructured data. Kibana is tied to it to visualize things.&nbsp;</div>
What is a client?	<div>a piece of hardware or software that accesses a service made available by a server. The server is often on another computer system in which case the client access it through a network.</div>
What is a REST API?	<div>REST is a paradigm of how to communicate between client/servers</div>
What is Jenkins?	<div>manages a continuous delivery pipeline, or a way of getting things from version control to production for your users and customers.</div>
What is batch processing?	<div>referring to running code on data without human intervention, for ETL pipelines, etc. Runs on a huge chunk of data at a time efficiently.</div>
What is JVM?	Java Virtual Machine: allows you to run Java code on any machine
What is a docker socket	TODO: need to look this up
What does curl do?	TODO: need to look this up
What is Gradle?	<ul> <li>This is just a script that does all the things you need to build a Scala jar or python package or whatever it is. It will build a virtual environment if needs, make sure your dependencies are there, etc. This allows you to avoid going step by step doing what you need to build something.</li><li>Similar to Makefile</li></ul>
What is an external table in hive?	An external table in hive is one that defines metadata/schema on top of external files. If you delete the table you only delete the schema not the data  can check table type with describe extended
How do you compare two spark tables?	Hash the rows and join on the hashed column, if count is equal to the two tables, then the two tables are equal
What is a JAVA HEAP ERROR in Spark?	This is a common error where the executor memory is too low.
What is the docker context?	This is the set of files where we are build the image.
What is the Docker engine?	this is the runtime and packaging tool, must be installed on host machine.
What 3 things does a docker container include?	1. An image<div>2. an execution environment</div><div>3. a standard set of instructions</div>
What is artifactory?	This is a location where you can push artifacts such as docker images, python packages, etc.
What is Influx and Prometheus?	<ul> <li>Time series database, for long running applications, performance over time for long things, Grafana that can run on top of these databases</li></ul>
Why use median? What is the mode?	Robust to outliers and skewed data. Mode is the most commonly occuring value
How do you maximixe a continuous function for single variable? How do you maximize for multivariate? What is the role of the second derivative.	Take the derivative, set to 0 and solve for x. You know if its maximum or minimum by the second derivative, if second derivative is positive then minimum. If it is 0 then it is a saddle point. Another way is to calculate the derivative on each side of the critical point.<div><br></div><div>If gradient vector is the 0 vector then we know we are at a critical point. Find the Hessian which is the Jacobian of the gradient. If the determinant of the hessian is less than zero then its a saddle point. If its 0 then test is inconclusive. If its greater than 0 then look at the sign of the second derivative in any direction, if positive then minimum.</div>
How do you know if you are differenced enough for a time series?	<div>&nbsp;check the auto correlation plot, should be closer to zero or maybe even negative</div>
How does k-folds allow us to use our data more effectively?	<ul>  <li>We can do training and tuning on more data, while still having a set for measuring generalizability</li> </ul>
What are content based recommendations in the context of a recommendation system?	Get the items that have been bought embedded into some space and then compare with other items and recommend from there
What is collaborative filtering?	<ul>   <li>Focuses on finding similar users in the purchase or rating space. So for Matt Goodwin having bought our of N possible things then we find customers who bought similar things, eliminate the things that I already bought, and recommend the things I haven’t bought that customers similar to me bought. Might be simple averaging, or weighted averaging based on similarity.</li> <li>Problem with this however is that there are a lot of users and users vectors can be unstable</li>  </ul>
What is item-item collaborative filtering?	<ul>   <li>Focus on users purchases and rated items and getting similar items</li> <ul> <li>Creates a similarity matrix between each pair of items</li> <li>The similarity metric can be the cosine distance between two item vectors of length M where M is the number of customers</li> <li>A vector of 1’s and 0’s</li> <li>For multiple items, we aggregate and choose the most popular items</li> </ul> <li>More stable if there are more users than items, and faster</li>  </ul>
What is Hotellings T^2?	This is a multivariate test that tests the equality of vectors. TODO: Fill this out more
How to find outliers?	If univariate box-plots, standard deviations, Cooks distance(TODO look this up)<div><br></div><div>Multivariate would include Mahalanobis distance, transform then Mahalanobis, weird relationships between variables (TODO find more options)</div>
What are influential points?	Outliers that affect the model - if you remove them then the model changes drastically. If independent variable then it is a point of high leverage, if dependent then it is called an outlier.&nbsp;
How to deal with outliers?	"1. Drop them - if we feel they are mistakes and we have a lot of data not a bad strategy<div>2. Winsorsizing (set the high percentile points to the 90th percentile for example).</div><div>3. Binning</div><div>4. Decision trees can be robust because split points are not determined by the values of the independent variables, gradient boosting trees may not be robust however, because they weigh poorly predicted points higher, allowing the outlier to have more influence.</div><div>5. Use MAE as loss function<br><div><br></div><div>Outlier is different than a ""novelty"" point.<br></div></div>"
What is a partial dependence plot?	<ul>  <li>On your training data, for the feature you are interested in, vary that feature, plug it into the model at each instance, and average over all of your data points. This shows the relationship between the feature and the response variable</li> <ul> <li>If there are interactions that can be an issue</li> <li>Has a causal interpretation (change the feature value this is what happens). Doesn’t necessarily apply to the real world.</li> </ul> </ul>
What is individual conditional expectation?	<ul> <ul><li>Just pdp but for the individual instances</li> </ul></ul>
What is permutation importance?	This is a feature importance method that permutes every feature, gets model metrics of permuted dataset and finds which permuted feature hurt the model the most - this would be the most important.<div><br></div><div><div>Do it on validation set to get a sense of which features are most important for generalizability</div></div>
